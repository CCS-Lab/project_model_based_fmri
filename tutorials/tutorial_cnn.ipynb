{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial for MB-MVPA using task-fMRI data of Mixed-gamble task by Tom et al., 2007. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the MB-MVPA libarary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other libraries(nilean, keras, etc..) dosen't need to be imported.<br>\n",
    "Because mb-mvpa has wrapping the libararies.<br>\n",
    "You don't necessarily have to know fMRI libraries like nilearn and machine learning libraries like tensorflow.<br>\n",
    "<b>MB-MVPA is all you need.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of mb-mvpa are wrapping nilearn, tensorflow, Keras and etc., so warning can occur from that libraries.<br>\n",
    "This page does not print warning because most of them are can be ignored.<br>\n",
    "You don't need to remove the warning when you are actually using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheoljun/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/nilearn/glm/__init__.py:56: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  'It may change in any future release of Nilearn.', FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from mbmvpa.preprocessing.preprocess import DataPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: add original data download link\n",
    "\n",
    "Data download from AWS S3, ~ <b>1GB</b> (would be under the \"Mixed-gamble_task/example_data/\").<br>\n",
    "\n",
    "We provide a small subset (2 subjects) of original Tom's dataset (16 subjects). The fMRI images in the example is preprocessed by conventional fMRI preprocessing pipeline by using \n",
    "[*fmriprep*](https://fmriprep.org/en/stable/) v.20.1.0. Please refer to the [original](https://openneuro.org/datasets/ds000005/versions/00001) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root = load_example_data(\"tom\")\n",
    "root = \"/data2/project_modelbasedMVPA/ds000005\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing fMRI images and behavioral data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MB-MVPA requires primariliy preprocessed task-fMRI experiments data fromatted in conventional [BIDS format](https://bids-specification.readthedocs.io/en/stable/) \n",
    "\n",
    "It expects the following organized files. All the naming conventions used here conform with outputs from *fmriprep* v.20.1.0. by Poldrack lab.\n",
    "\n",
    "The fMRI images are usually located here<br>\n",
    "<i>{BIDS_ROOT}/derivatives/fmriprep/subject/session/run/func/*nii.gz</i><br>\n",
    "And the behavior data are located here<br>\n",
    "<i>{BIDS_ROOT}/subject/session/run/func/*.tsv</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.39 minutes\n"
     ]
    }
   ],
   "source": [
    "s = perf_counter()\n",
    "\n",
    "dm_model = 'ra_prospect'\n",
    "\n",
    "def example_adjust(row):\n",
    "    ## rename data in a row to the name which can match hbayesdm.ra_prospect requirements ##\n",
    "    row[\"gamble\"] = 1 if row[\"respcat\"] == 1 else 0\n",
    "    row[\"cert\"] = 0\n",
    "    return row\n",
    "\n",
    "def example_filter(row):\n",
    "    # include all trial data\n",
    "    return True\n",
    "\n",
    "def example_latent(row, param_dict):\n",
    "    ## calculate subjectives utility for choosing Gamble over Safe option\n",
    "    ## prospect theory with loss aversion and risk aversion is adopted\n",
    "    modulation = (row[\"gain\"] ** param_dict[\"rho\"]) - (param_dict[\"lambda\"] * (row[\"loss\"] ** param_dict[\"rho\"]))\n",
    "    row[\"modulation\"] = modulation\n",
    "    return row\n",
    "\n",
    "\n",
    "preprocessor = DataPreprocessor(bids_layout=root,\n",
    "                               adjust_function=example_adjust,\n",
    "                               filter_function=example_filter,\n",
    "                               latent_function=example_latent,\n",
    "                               dm_model=dm_model)\n",
    "print(f\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  fMRIPrep  ] BIDS Layout: .../ds000005/derivatives/fmriprep | Subjects: 16 | Sessions: 0 | Runs: 48\n",
      "[  MB-MVPA   ] BIDS Layout: ...PA/ds000005/derivatives/mbmvpa | Subjects: 16 | Sessions: 0 | Runs: 48\n"
     ]
    }
   ],
   "source": [
    "preprocessor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached StanModel: cached-ra_prospect-pystan_2.19.1.1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Automatic Differentiation Variational Inference (ADVI) is an EXPERIMENTAL ALGORITHM.\n",
      "WARNING:pystan:ADVI samples may be found on the filesystem in the file `/tmp/tmp2zp8j2ra/output.csv`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model  = ra_prospect\n",
      "Data   = <pandas.DataFrame object>\n",
      "\n",
      "Details:\n",
      " # of chains                    = 4\n",
      " # of cores used                = 1\n",
      " # of MCMC samples (per chain)  = 4000\n",
      " # of burn-in samples           = 1000\n",
      " # of subjects                  = 16\n",
      " # of (max) trials per subject  = 256\n",
      "\n",
      "Using cached StanModel: cached-ra_prospect-pystan_2.19.1.1.pkl\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<class 'stanfit4ra_prospect_39661c43d0c77275c6781f36a16d9609_6009202008874363709.PyStanHolder'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fe68c4c07507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/mb_mvpa-0.2.0-py3.7.egg/mbmvpa/preprocessing/preprocess.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, overwrite, process_name, feature_name, motion_confounds, n_thread, dm_model, individual_params, df_events, adjust_function, filter_function, skip_modeling, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m                                                     \u001b[0madjust_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madjust_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                                                     \u001b[0mfilter_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                                                     **kwargs)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         self.y_generator.run(overwrite=overwrite,\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/mb_mvpa-0.2.0-py3.7.egg/mbmvpa/preprocessing/events.py\u001b[0m in \u001b[0;36mset_computational_model\u001b[0;34m(self, overwrite, dm_model, individual_params, df_events, adjust_function, filter_function, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mhbayesdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_events\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mindividual_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_ind_pars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/hbayesdm/models/_ra_prospect.py\u001b[0m in \u001b[0;36mra_prospect\u001b[0;34m(data, niter, nwarmup, nchain, ncore, nthin, inits, ind_pars, model_regressor, vb, inc_postpred, adapt_delta, stepsize, max_treedepth, **additional_args)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mstepsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstepsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mmax_treedepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_treedepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         **additional_args)\n\u001b[0m",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/hbayesdm/models/_ra_prospect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             ]),\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         )\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/hbayesdm/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, task_name, model_name, model_type, data_columns, parameters, regressors, postpreds, parameters_desc, additional_args_desc, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Run model function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_ind_pars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpar_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_regressor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/hbayesdm/base.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, data, niter, nwarmup, nchain, ncore, nthin, inits, ind_pars, model_regressor, vb, inc_postpred, adapt_delta, stepsize, max_treedepth, **additional_args)\u001b[0m\n\u001b[1;32m    172\u001b[0m         fit = self._fit_stan_model(\n\u001b[1;32m    173\u001b[0m             \u001b[0mvb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mniter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnwarmup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             adapt_delta, stepsize, max_treedepth, ncore)\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mmeasure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_measure_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind_pars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/hbayesdm/base.py\u001b[0m in \u001b[0;36m_fit_stan_model\u001b[0;34m(self, vb, sm, data_dict, pars, gen_init, nchain, niter, nwarmup, nthin, adapt_delta, stepsize, max_treedepth, ncore)\u001b[0m\n\u001b[1;32m    720\u001b[0m                                         \u001b[0;34m'stepsize'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstepsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m                                         'max_treedepth': max_treedepth},\n\u001b[0;32m--> 722\u001b[0;31m                                n_jobs=ncore)\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_define_measure_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_pars\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/pystan/model.py\u001b[0m in \u001b[0;36msampling\u001b[0;34m(self, data, pars, chains, iter, warmup, thin, seed, init, sample_file, diagnostic_file, verbose, algorithm, control, n_jobs, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0mcall_sampler_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mizip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0mcall_sampler_star\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_sampler_star\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0mret_and_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_sampler_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_sampler_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msmpl\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret_and_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/pystan/model.py\u001b[0m in \u001b[0;36m_map_parallel\u001b[0;34m(function, args, n_jobs)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mmap_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mstanfit4ra_prospect_39661c43d0c77275c6781f36a16d9609_6009202008874363709.pyx\u001b[0m in \u001b[0;36mstanfit4ra_prospect_39661c43d0c77275c6781f36a16d9609_6009202008874363709._call_sampler_star\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mstanfit4ra_prospect_39661c43d0c77275c6781f36a16d9609_6009202008874363709.pyx\u001b[0m in \u001b[0;36mstanfit4ra_prospect_39661c43d0c77275c6781f36a16d9609_6009202008874363709._call_sampler\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mstanfit4ra_prospect_39661c43d0c77275c6781f36a16d9609_6009202008874363709.pyx\u001b[0m in \u001b[0;36mstanfit4ra_prospect_39661c43d0c77275c6781f36a16d9609_6009202008874363709._pystanholder_from_stanholder\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <class 'stanfit4ra_prospect_39661c43d0c77275c6781f36a16d9609_6009202008874363709.PyStanHolder'> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "s = perf_counter()\n",
    "\n",
    "preprocessor.preprocess(overwrite=False)\n",
    "\n",
    "print(f\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and shape check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.data.loader import BIDSDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/data2/project_modelbasedMVPA/ds000005\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.24 minutes\n"
     ]
    }
   ],
   "source": [
    "s = perf_counter()\n",
    "\n",
    "loader = BIDSDataLoader(layout=root)\n",
    "X,y = loader.get_total_data(reconstruct=True)\n",
    "\n",
    "print(f\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X\", X.shape)\n",
    "print(\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_mask = loader.get_voxel_mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting MVPA models & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.models.mvpa_cnn import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MVPA_model = CNN(X=X,\n",
    "                y=y,\n",
    "                n_repeat=15,\n",
    "                voxel_mask = voxel_mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001] - val_loss: 0.1239\n",
      "[002] - val_loss: 0.1248\n",
      "[003] - val_loss: 0.1248\n",
      "[004] - val_loss: 0.1226\n",
      "[005] - val_loss: 0.1294\n",
      "[006] - val_loss: 0.1255\n",
      "[007] - val_loss: 0.1362\n",
      "[008] - val_loss: 0.1389\n",
      "[009] - val_loss: 0.1469\n",
      "[010] - val_loss: 0.1423\n",
      "[011] - val_loss: 0.1569\n",
      "[012] - val_loss: 0.1501\n",
      "[013] - val_loss: 0.1426\n",
      "[014] - val_loss: 0.1583\n",
      "[015] - val_loss: 0.1713\n",
      "[016] - val_loss: 0.1502\n",
      "[017] - val_loss: 0.1586\n",
      "[018] - val_loss: 0.1559\n",
      "[019] - val_loss: 0.1575\n",
      "[020] - val_loss: 0.1682\n",
      "[021] - val_loss: 0.1528\n",
      "[022] - val_loss: 0.1587\n"
     ]
    }
   ],
   "source": [
    "s = perf_counter()\n",
    "\n",
    "coeffs = MVPA_model.run()\n",
    "\n",
    "print(f\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = perf_counter()\n",
    "\n",
    "sham_errors = MVPA_model.sham()\n",
    "\n",
    "print(f\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = MVPA_model.image(save_path='.', task_name='example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-based-fmri-A7ELC43w-py3.7",
   "language": "python",
   "name": "model-based-fmri-a7elc43w-py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
