{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial for MB-MVPA using task-fMRI data of Mixed-gamble task by Tom et al., 2007. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the MB-MVPA libarary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other libraries(nilean, keras, etc..) dosen't need to be imported.<br>\n",
    "Because mb-mvpa has wrapping the libararies.<br>\n",
    "You don't necessarily have to know fMRI libraries like nilearn and machine learning libraries like tensorflow.<br>\n",
    "<b>MB-MVPA is all you need.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of mb-mvpa are wrapping nilearn, tensorflow, Keras and etc., so warning can occur from that libraries.<br>\n",
    "This page does not print warning because most of them are can be ignored.<br>\n",
    "You don't need to remove the warning when you are actually using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.preprocessing.preprocess import DataPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: add original data download link\n",
    "\n",
    "Data download from AWS S3, ~ <b>1GB</b> (would be under the \"Mixed-gamble_task/example_data/\").<br>\n",
    "\n",
    "We provide a small subset (2 subjects) of original Tom's dataset (16 subjects). The fMRI images in the example is preprocessed by conventional fMRI preprocessing pipeline by using \n",
    "[*fmriprep*](https://fmriprep.org/en/stable/) v.20.1.0. Please refer to the [original](https://openneuro.org/datasets/ds000005/versions/00001) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root = load_example_data(\"tom\")\n",
    "root = \"/data2/project_modelbasedMVPA/ds000005\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing fMRI images and behavioral data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MB-MVPA requires primariliy preprocessed task-fMRI experiments data fromatted in conventional [BIDS format](https://bids-specification.readthedocs.io/en/stable/) \n",
    "\n",
    "It expects the following organized files. All the naming conventions used here conform with outputs from *fmriprep* v.20.1.0. by Poldrack lab.\n",
    "\n",
    "The fMRI images are usually located here<br>\n",
    "<i>{BIDS_ROOT}/derivatives/fmriprep/subject/session/run/func/*nii.gz</i><br>\n",
    "And the behavior data are located here<br>\n",
    "<i>{BIDS_ROOT}/subject/session/run/func/*.tsv</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_model = 'ra_prospect'\n",
    "\n",
    "def example_adjust(row):\n",
    "    ## rename data in a row to the name which can match hbayesdm.ra_prospect requirements ##\n",
    "    row[\"gamble\"] = 1 if row[\"respcat\"] == 1 else 0\n",
    "    row[\"cert\"] = 0\n",
    "    return row\n",
    "\n",
    "def example_filter(row):\n",
    "    # include all trial data\n",
    "    return True\n",
    "\n",
    "def example_latent(row, param_dict):\n",
    "    ## calculate subjectives utility for choosing Gamble over Safe option\n",
    "    ## prospect theory with loss aversion and risk aversion is adopted\n",
    "    modulation = (row[\"gain\"] ** param_dict[\"rho\"]) - (param_dict[\"lambda\"] * (row[\"loss\"] ** param_dict[\"rho\"]))\n",
    "    row[\"modulation\"] = modulation\n",
    "    return row\n",
    "\n",
    "\n",
    "preprocessor = DataPreprocessor(bids_layout=root,\n",
    "                               adjust_function=example_adjust,\n",
    "                               filter_function=example_filter,\n",
    "                               latent_function=example_latent,\n",
    "                               dm_model=dm_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  fMRIPrep  ] BIDS Layout: .../ds000005/derivatives/fmriprep | Subjects: 16 | Sessions: 0 | Runs: 48\n",
      "[  MB-MVPA   ] BIDS Layout: ...PA/ds000005/derivatives/mbmvpa | Subjects: 0 | Sessions: 0 | Runs: 0\n"
     ]
    }
   ],
   "source": [
    "preprocessor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.preprocess(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and shape check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the above process, <b><i>subject, session and run-wise fMRI images and modulation values are obtained</i></b><br>\n",
    "<b><i>Both X(fMRI), y(modulation)'s shape[0] must equal.</i></b><br>\n",
    "The <b><i>prepare_dataset</i></b> function operate shape check and time and voxel masking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "def prepare_dataset(\n",
    "    root, # (str or pathlib.Path): Path where created data (X, y, time_mask, voxel_mask) is stored.\n",
    "    time_masking=True, # (bool): Whether to do time masking or not.\n",
    "    voxel_masking=True # (bool): Whether to do voxel masking or not.\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, voxel_mask = prepare_dataset(data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>X (numpy.ndarray)</i></b>: X, which is adjusted dimension and masked time points for training with shape: data # x voxel #.<br>\n",
    "<b><i>y (numpy.ndarray)</i></b>: y, which is adjusted dimension and masked time points for training with shape: data #.<br>\n",
    "<b><i>voxel_mask (nibabel.nifti1.Nifti1Image)</i></b>: Voxel mask file for get result brain map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting MVPA models & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.utils.coef2map import get_map\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.models.regressor import penalized_linear_regression\n",
    "\n",
    "s = perf_counter()\n",
    "coefs = penalized_linear_regression(X, y,\n",
    "                                    layout,\n",
    "                                    lambda_param=2.0,\n",
    "                                    N=10,\n",
    "                                    verbose=1)\n",
    "result = get_map(coefs, voxel_mask, task_name=\"tom2007_penalized_linear\", map_type=\"z\", save_path=\".\", sigma=1)\n",
    "print(f\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.models.regressor import mlp_regression\n",
    "\n",
    "s = perf_counter()\n",
    "coefs = mlp_regression(X, y,\n",
    "                       layout,\n",
    "                       layer_dims=[1024, 1024],\n",
    "                       activation=\"linear\",\n",
    "                       dropout_rate=0.5,\n",
    "                       epochs=100,\n",
    "                       patience=10,\n",
    "                       batch_size=64,\n",
    "                       N=3,\n",
    "                       verbose=1)\n",
    "result = get_map(coefs, voxel_mask, task_name=\"tom2007_mlp\", map_type=\"z\", save_path=\".\", sigma=1)\n",
    "print(f\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.models.regressor import elasticnet\n",
    "\n",
    "s = perf_counter()\n",
    "coefs = elasticnet(X, y,\n",
    "                   layout,\n",
    "                   n_jobs=16,\n",
    "                   verbose=1,\n",
    "                   max_lambda=1,\n",
    "                   n_samples=5000)\n",
    "result = get_map(coefs, voxel_mask, task_name=\"tom2007_elasticnet\", map_type=\"z\", save_path=\".\", sigma=1)\n",
    "print(f\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-based-fmri-A7ELC43w-py3.7",
   "language": "python",
   "name": "model-based-fmri-a7elc43w-py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
