{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed-gamble Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is an MB-MVPA code that uses part of the data (Tom et al., 2007).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the MB-MVPA libarary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other libraries(nilean, keras, etc..) dosen't need to be imported.<br>\n",
    "Because mb-mvpa has wrapping the libararies.<br>\n",
    "You don't necessarily have to know fMRI libraries like nilearn and machine learning libraries like tensorflow.<br>\n",
    "<b>MB-MVPA is all you need.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of mb-mvpa are wrapping nilearn, tensorflow, Keras and etc., so warning can occur from that libraries.<br>\n",
    "This page does not print warning because most of them are can be ignored.<br>\n",
    "You don't need to remove the warning when you are actually using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.preprocessing.bids import bids_preprocess\n",
    "from mbmvpa.preprocessing.events import events_preprocess\n",
    "from mbmvpa.data.loader import prepare_dataset\n",
    "from mbmvpa.utils.example_utils import load_example_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data download from AWS S3, ~ <b>1GB</b> (would be under the \"Mixed-gamble_task/example_data/\").<br>\n",
    "\n",
    "We provide a small subset (2 subjects) of original Tom's dataset (16 subjects). The fMRI images in the example is preprocessed by conventional fMRI preprocessing pipeline by using \n",
    "[*fmriprep*](https://fmriprep.org/en/stable/) v.20.1.0. Please refer to the [original](https://openneuro.org/datasets/ds000005/versions/00001) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 986M/986M [00:26<00:00, 37.3MiB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load success! (tom)\n"
     ]
    }
   ],
   "source": [
    "root = load_example_data(\"tom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing fMRI images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MB-MVPA requires primariliy preprocessed task-fMRI experiments data fromatted in conventional [BIDS format](https://bids-specification.readthedocs.io/en/stable/) \n",
    "\n",
    "It expects the following organized files. All the naming conventions used here conform with outputs from *fmriprep* v.20.1.0. by Poldrack lab.\n",
    "\n",
    "The fMRI images are usually located here<br>\n",
    "<i>{BIDS_ROOT}/derivatives/fmriprep/subject/session/run/func/*nii.gz</i><br>\n",
    "And the behavior data are located here<br>\n",
    "<i>{BIDS_ROOT}/subject/session/run/func/*.tsv</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "def bids_preprocess(\n",
    "    root, # (str or Path): the root directory of BIDS layout.\n",
    "    layout, # (bids.BIDSLayout): BIDSLayout by bids package. if not provided, it will be obtained from root path.\n",
    "    save_path, # (str or Path): a path for the directory to save output (X, voxel_mask).\n",
    "    mask_path, # (str or Path): a path for the directory containing mask files (nii or nii.gz). encourage get files from Neurosynth.\n",
    "    threshold, # (float): threshold for binarizing mask images\n",
    "    zoom, # (tuple[float, float, float]): zoom window, indicating a scaling factor for each dimension in x,y,z.\n",
    "    smoothing_fwhm, # (int or None): the amount of spatial smoothing. if None, image will not be smoothed.\n",
    "    interpolation_func, # (numpy.function): a method to calculate a representative value in the zooming window.\n",
    "    standardize, # (bool): if true, conduct standard normalization within each image of a single run.\n",
    "    motion_confounds, # (list[str, str, ..., str]): list of motion confound names in confounds tsv file. \n",
    "    ncore, # int): the number of core for the tparallel computing.\n",
    "    nthread, # (int): the number of thread for the parallel computing.\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bids preprocessing done!                          : 100%|██████████| 6/6 [00:23<00:00,  5.75s/it] "
     ]
    }
   ],
   "source": [
    "X, voxel_mask, layout, data_root = bids_preprocess(root, smoothing_fwhm=None, zoom=(2, 2, 2), ncore=2, nthread=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>X</i> (<i>numpy.ndarray</i>)</b>: subject-wise & run-wise BOLD time series data.<br>\n",
    "<b><i>voxel_mask</i> (<i>nibabel.nifti1.Nifti1Image</i>)</b>: a nifti image for voxel-wise binary mask (ROI mask)<br>\n",
    "<b><i>layout</i> (<i>bids.layout</i>)</b>: The loaded layout.<br>\n",
    "<b><i>data_root</i> (<i>str</i>)</b>: Equal to layout.derivatives[\"fMRI\"].root."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing bids data (events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our mbmvpa is directly inputted into the data and modulation functions to be used to increase user's freedom and increase stability.<br>\n",
    "The following three functions must be completed, each of which means:<br>\n",
    "1. If you use <b><i>hbayesDM</i></b>, you should change the columns name to suit it. -> <i>preprocess_columns</i><br>\n",
    "2. If you only want to use behavioral data under certain conditions, you must define a condition function. -> <i>condition</i><br>\n",
    "3. Finally, since we are model-based fMRI, we have to calculate the modulation.<br>\n",
    "   The important point is that the behavioral data that we already have are in the <b><i>row</i></b>, and parameters estimated by model are in the <b><i>param_dict</i></b>.<br>\n",
    "   -> <i>modulation</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have parameters already calculated and can provide them in *.tsv*, we also allow that.<br>\n",
    "<b><i>individual_params_custom</i></b> has the role.<br>\n",
    "In that case, the dm_model, or deicison making model, is not required but modulation functions is still required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "def example_tom_preprocess_columns(row):\n",
    "    ## rename data in a row to the name which can match hbayesdm.ra_prospect requirements ##\n",
    "    row[\"gamble\"] = 1 if row[\"respcat\"] == 1 else 0\n",
    "    row[\"cert\"] = 0\n",
    "    return row\n",
    "\n",
    "def example_tom_condition(row):\n",
    "    # include all trial data\n",
    "    return True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we used individual parameters created by the above two functions.<br>\n",
    "But, still required modulation function like bellow.<br>\n",
    "If you want to skip even this, you need to pass a dataframe with <b><i>modulation, subjID, run, onset, duration</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_tom_modulation(row, param_dict):\n",
    "    ## calculate subjectives utility for choosing Gamble over Safe option\n",
    "    ## prospect theory with loss aversion and risk aversion is adopted\n",
    "    modulation = (row[\"gain\"] ** param_dict[\"rho\"]) - (param_dict[\"lambda\"] * (row[\"loss\"] ** param_dict[\"rho\"]))\n",
    "    row[\"modulation\"] = modulation\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know more about the equation above, please refer to this.<br>\n",
    "https://ccs-lab.github.io/hBayesDM/reference/ra_prospect.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "def events_preprocess(\n",
    "    root, # (str or Path): The root directory of BIDS layout\n",
    "    layout, # (bids.BIDSLayout): BIDSLayout by bids package. if not provided, it will be obtained from root path.\n",
    "    save_path, # (str or Path): A path for the directory to save outputs (y, time_mask) and intermediate data (individual_params_custom, df_events).\n",
    "    preprocess, # preprocess (function(pandas.Series, dict)-> pandas.Series)): A user-defined function for modifying each row of behavioral data.\n",
    "    condition, # (function(pandas.Series)-> boolean)): A user-defined function for filtering each row of behavioral data.\n",
    "    modulation, # (function(pandas.Series, dict)-> Series): A user-defined function for calculating latent process (modulation).\n",
    "    condition_for_modeling, # (None or function(pandas.Series)-> boolean)): A user-defined function for filtering each row of behavioral data.\n",
    "    dm_model, # (str or pathlib.Path or hbayesdm.models): Computational model by hBayesDM package. should be provided as the name of the model\n",
    "    individual_params_custom, # (None or str or Path or pandas.DataFrame): pandas dataframe with params_name columns and corresponding values for each subject.\n",
    "    hrf_model, # (str): The name for hemodynamic response function, which will be convoluted with event data to make BOLD-like signal.\n",
    "    normalizer, # (str): A name for normalization method, which will normalize BOLDified signal.\n",
    "    df_events_custom, # (str or Path or pandas.DataFrame)\n",
    "    use_duration, # (boolean): If True use \"duration\" column to make time mask, if not regard gap between consecuting trials\" onset values as duration\n",
    "    scale, # (tuple(float, float)): Lower bound and upper bound for minmax scaling.\n",
    "    **kwargs # keyward arguments for hbayesdm.models.\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_model, df_events, signals, time_masks, _ = \\\n",
    "    events_preprocess(root,\n",
    "                      modulation=example_tom_modulation,\n",
    "                      individual_params_custom=\"../example_data/tom_example/derivatives/fmriprep/mvpa/individual_params.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>dm_model (str or hbayesdm.models)</i></b>: hBayesDM model or it's name.<br>\n",
    "<b><i>df_events (pandas.DataFrame)</i></b>: Integrated events DataFrame (preprocessed if not provided) with <b><i>onset, duration, modulation.</i></b><br>\n",
    "<b><i>signals (numpy.ndarray)</i></b>: BOLD-like signals with shape: <b><i>subject # x (session # x run #) x time length of scan x voxel #</i></b>.<br>\n",
    "<b><i>time_mask (numpy.ndarray)</i></b>: A binary mask indicating valid time point with shape: <b><i>subject # x (session # x run #) x time length of scan.</i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and shape check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the above process, <b><i>subject, session and run-wise fMRI images and modulation values are obtained</i></b><br>\n",
    "<b><i>Both X(fMRI), y(modulation)'s shape[0] must equal.</i></b><br>\n",
    "The <b><i>prepare_dataset</i></b> function operate shape check and time and voxel masking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "def prepare_dataset(\n",
    "    root, # (str or pathlib.Path): Path where created data (X, y, time_mask, voxel_mask) is stored.\n",
    "    time_masking=True, # (bool): Whether to do time masking or not.\n",
    "    voxel_masking=True # (bool): Whether to do voxel masking or not.\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, voxel_mask = prepare_dataset(data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><i>X (numpy.ndarray)</i></b>: X, which is adjusted dimension and masked time points for training with shape: data # x voxel #.<br>\n",
    "<b><i>y (numpy.ndarray)</i></b>: y, which is adjusted dimension and masked time points for training with shape: data #.<br>\n",
    "<b><i>voxel_mask (nibabel.nifti1.Nifti1Image)</i></b>: Voxel mask file for get result brain map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting MVPA models & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.utils.coef2map import get_map\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.models.regressor import penalized_linear_regression\n",
    "\n",
    "s = perf_counter()\n",
    "coefs = penalized_linear_regression(X, y,\n",
    "                                    layout,\n",
    "                                    lambda_param=2.0,\n",
    "                                    N=10,\n",
    "                                    verbose=1)\n",
    "result = get_map(coefs, voxel_mask, task_name=\"tom2007_penalized_linear\", map_type=\"z\", save_path=\".\", sigma=1)\n",
    "print(f\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.models.regressor import mlp_regression\n",
    "\n",
    "s = perf_counter()\n",
    "coefs = mlp_regression(X, y,\n",
    "                       layout,\n",
    "                       layer_dims=[1024, 1024],\n",
    "                       activation=\"linear\",\n",
    "                       dropout_rate=0.5,\n",
    "                       epochs=100,\n",
    "                       patience=10,\n",
    "                       batch_size=64,\n",
    "                       N=3,\n",
    "                       verbose=1)\n",
    "result = get_map(coefs, voxel_mask, task_name=\"tom2007_mlp\", map_type=\"z\", save_path=\".\", sigma=1)\n",
    "print(f\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.models.regressor import elasticnet\n",
    "\n",
    "s = perf_counter()\n",
    "coefs = elasticnet(X, y,\n",
    "                   layout,\n",
    "                   n_jobs=16,\n",
    "                   verbose=1,\n",
    "                   max_lambda=1,\n",
    "                   n_samples=5000)\n",
    "result = get_map(coefs, voxel_mask, task_name=\"tom2007_elasticnet\", map_type=\"z\", save_path=\".\", sigma=1)\n",
    "print(f\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-based-fmri-A7ELC43w-py3.7",
   "language": "python",
   "name": "model-based-fmri-a7elc43w-py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
