{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: model-based MVPA using MBfMRI\n",
    "\n",
    "This tutorial offers guidance to perform model-based MVPA with a few lines of codes using MBfMRI package.<br>\n",
    "You only need to prepare a root path for task-based fMRI data (in BIDS layout) and the preprocessed images under the path.\n",
    "\n",
    "For model-based GLM using MBfMRI, see [here](#MBGLM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow of MVPA approach, model-based MVPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact workflow of the model-based MVPA consists of the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=https://raw.githubusercontent.com/CCS-Lab/project_model_based_fmri/main/images/mbmvpa_workflow.png width=\"800px\"><\\center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Generate latent process signals** by fitting computational models with behavioral data and extracting time-series of latent process followed by HRF convolution.\n",
    "\n",
    "2. **Generate multi-voxel signals** from preprocess fMRI images by allowing ROI masking, zooming spatial resolution, and improving the quality of signals by several well-established methods (e.g. detrending, high-pass filtering, regressing out confounds).\n",
    "\n",
    "3. **Train MVPA models** by feeding multi-voxel signals as input (X) and latent process signals as ouput (y), or target, employing the repeated cross-validation framework. \n",
    "\n",
    "4. **Interpret the trained MVPA models** to visualize the brain implementation of the target latent process quantified as brain activation pattern attributed  to predict the target signals from the multi-voxel signals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need following packages installed on your device:\n",
    "* Python 3.6 or above is required. Python is freely available from https://www.python.org/\n",
    "* Poetry is required to set up the virtual environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to install MBfMRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clone the repository:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/CCS-Lab/project_model_based_fmri.git\n",
    "```\n",
    "\n",
    "On the cloned repository on your device:\n",
    "```bash\n",
    "cd project_model_based_fmri\n",
    "poetry install\n",
    "```\n",
    "\n",
    "Then, you can open the installed environment:\n",
    "```bash\n",
    "poetry shell\n",
    "```\n",
    "\n",
    "Set up the package:\n",
    "```bash\n",
    "python setup.py install\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use MBfMRI with jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use MBfMRI with Python script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aforementioned procedures can be done by a single function, `mbfmri.core.engine.run_mbfmri`.<br>\n",
    "The configuration of analysis can be controlled by various arguments, so users can choose which kinds of approach to apply, latent processes of interest, and so on. These settings can be manipulated by relevant keyworded argument (e.g. `run_mbfmri(..., mvpa_model='mlp',...)` or `run_mbfmri(...,process_name='PE_chosen')`).\n",
    "```python\n",
    "from mbfmri.core.engine import run_mbfmri\n",
    "\n",
    "_ = run_mbfmri(bids_layout='mini_bornstein2017',    # the root folder of a BIDS valid dataset\n",
    "               task_name='multiarmedbandit',        # task ID\n",
    "               dm_model= 'banditNarm_lapse_decay',  # computational model\n",
    "               process_name='PEchosen'              # identifier for target latent process\n",
    "               \n",
    "               ##################################################################################\n",
    "               #                                                                                #\n",
    "               #                ANY KEYWARDED ARGUMENT DEFINED IN CONFIGURATION                 #\n",
    "               #                                                                                #\n",
    "               ##################################################################################\n",
    "               )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This tutorial will introduce what to decide and how to set some keyworded arguments before running the code.\n",
    "\n",
    "Please refer to the [document](https://project-model-based-fmri.readthedocs.io/en/latest/mbfmri.core.html#mbfmri-core-engine-run-mbfmri) for the full list of configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Example data]\n",
    "\n",
    "The example data is a mini-size version of the dataset issued by Bornstein et al., 2017 ([paper](https://www.nature.com/articles/nn.4573#abstracthttps://www.nature.com/articles/nn.4573#abstract), [openneuro](https://openneuro.org/datasets/ds001607/versions/1.0.1)).<br>\n",
    "The data includes 8 subjects and each of them has one run for Reinforcement Learning task with 180 trials. <br>\n",
    "You can download the zip file from the [link]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "bids_layout = \"mini_bornstein2017\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run MBfMRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - What you should do/decide before running MBfMRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1. Data - Check input data](#Data)\n",
    "#### [2. Preprocessing 1 - Calculate latent process](#LatentProcess)\n",
    "#### [3. Preprocessing 2 - Generate voxel features](#VoxelFeatures)\n",
    "#### [4. fMRI Analysis](#fMRIAnalysis)\n",
    "#### [5. Run the code!](#Code)\n",
    "#### [6. Output](#Output)\n",
    "#### [7. Other examples](#Examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data - Check input data <a name = \"Data\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1. BIDS layout with original data\n",
    "\n",
    "The original task-based fMRI data should be in `bids_layout`.<br> \n",
    "Also, you need to place preprocessed fMRI images under the *derivatives* folder under `bids_layout`, named as `fmriprep`.<br>\n",
    "(In the original layoout of sample data, there are only events files as the preprocessed images will be used.)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_description.json  masks   sub-02  sub-04  sub-06  sub-08\n",
      "derivatives\t\t  sub-01  sub-03  sub-05  sub-07\n"
     ]
    }
   ],
   "source": [
    "# Check bids layout in the root\n",
    "!ls mini_bornstein2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The behavioral data should be in `events.tsv`, following the original BIDS layout as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>type</th>\n",
       "      <th>choice</th>\n",
       "      <th>rwdval</th>\n",
       "      <th>RT</th>\n",
       "      <th>time_feedback</th>\n",
       "      <th>gain</th>\n",
       "      <th>loss</th>\n",
       "      <th>PrecalculatedQchosen</th>\n",
       "      <th>PrecalculatedPEchosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.320</td>\n",
       "      <td>3</td>\n",
       "      <td>bandit</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2439</td>\n",
       "      <td>11.5639</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15.303</td>\n",
       "      <td>3</td>\n",
       "      <td>bandit</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7019</td>\n",
       "      <td>18.0049</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.897044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22.286</td>\n",
       "      <td>3</td>\n",
       "      <td>bandit</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>25.2511</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>29.269</td>\n",
       "      <td>3</td>\n",
       "      <td>bandit</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0103</td>\n",
       "      <td>32.2793</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.897044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>36.253</td>\n",
       "      <td>3</td>\n",
       "      <td>bandit</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4705</td>\n",
       "      <td>38.7235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.733677</td>\n",
       "      <td>-0.733677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   onset  duration    type  choice  rwdval      RT  \\\n",
       "0           0   8.320         3  bandit       1       0  1.2439   \n",
       "1           1  15.303         3  bandit       2      10  0.7019   \n",
       "2           2  22.286         3  bandit       3       0  0.9651   \n",
       "3           3  29.269         3  bandit       3      10  1.0103   \n",
       "4           4  36.253         3  bandit       2       0  0.4705   \n",
       "\n",
       "   time_feedback  gain  loss  PrecalculatedQchosen  PrecalculatedPEchosen  \n",
       "0        11.5639     0     0              0.000000               0.000000  \n",
       "1        18.0049    10     0              0.000000               4.897044  \n",
       "2        25.2511     0     0              0.000000               0.000000  \n",
       "3        32.2793    10     0              0.000000               4.897044  \n",
       "4        38.7235     0     0              0.733677              -0.733677  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check behavioral data\n",
    "import pandas as pd\n",
    "pd.read_table('mini_bornstein2017/sub-01/func/sub-01_task-multiarmedbandit_events.tsv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. Derivative layout from *fMRIPrep*\n",
    "\n",
    "The package assumes that preprocessing images is done by [fMRIPrep](https://fmriprep.org/en/stable/). <br>\n",
    "Please refer to [mbfmri/utils/config.py](https://github.com/CCS-Lab/project_model_based_fmri/blob/main/mbfmri/utils/config.py) for configuration of it.<br> \n",
    "\n",
    "If you preprocessed fMRI data using other tool than fMRIPrep, you should change the directory and file layout to apply MBfMRI package to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_description.json  sub-02  sub-04  sub-06  sub-08\n",
      "sub-01\t\t\t  sub-03  sub-05  sub-07\n"
     ]
    }
   ],
   "source": [
    "!ls mini_bornstein2017/derivatives/fmriprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-01_task-multiarmedbandit_desc-confounds_regressors.tsv\n",
      "sub-01_task-multiarmedbandit_space-MNI152NLin2009cAsym_desc-preproc_bold.json\n",
      "sub-01_task-multiarmedbandit_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\n"
     ]
    }
   ],
   "source": [
    "!ls mini_bornstein2017/derivatives/fmriprep/sub-01/func/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-3. Mask images\n",
    "\n",
    "The mask images would be located under the folder below as default `(BIDSroot/masks/include)`.<br>\n",
    "The images here are integrated into one binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gain_uniformity-test_z_FDR_0.01.nii.gz\n",
      " loss_association-test_z_FDR_0.01.nii.gz\n",
      " loss_uniformity-test_z_FDR_0.01.nii.gz\n",
      "'prediction error_association-test_z_FDR_0.01.nii.gz'\n",
      "'prediction error_uniformity-test_z_FDR_0.01.nii.gz'\n",
      " reward_association-test_z_FDR_0.01.nii.gz\n",
      " reward_uniformity-test_z_FDR_0.01.nii.gz\n"
     ]
    }
   ],
   "source": [
    "!ls mini_bornstein2017/masks/include\n",
    "# [??] what should I do if I want to use other mask images?\n",
    "# [CJ] Maybe we should discuss through Zoom about this. \n",
    "#      I am looking for appropriate and easy explanation for this function.\n",
    "#      It might be better to refer to \"_build_mask\" function codes located in\n",
    "#      mbfmri/utils/bold_utils.py. The mechanism is quite straightforward.\n",
    "# [??] And what's the purpose of this mask images?\n",
    "# [CJ] One of the major purposes is reducing the number of features (which is not applicable in CNN),\n",
    "#      and another would be to restrict regions which are supposed be included or excluded in MVPA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing 1 - Caculate latent process <a name = \"LatentProcess\"> </a>\n",
    "Choose cognitive model and target latent process to analyze in hBayesDM (or prepare precaculated latent process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1. hBayesDM model\n",
    "\n",
    "Now you need to choose which cognitive model to use. Please refer to [hBayesDM](https://hbayesdm.readthedocs.io/en/v1.0.1/models.html) and check available models.<br>\n",
    "- Here, the task used in the example data could be categorized as a **multi-armed bandit task** which requires subjects to learn the probability of three cards (or bandits) by rewards or none. So **a reinforcement learning model for multi-armed bandit task with 5 parameter (including decision noise and decay rate but not choice perseveration)** ([Niv et al., 2015](https://www.jneurosci.org/content/35/21/8145)) is chosen here for the example data. The model is named as `banditNarm_lapse_decay` in the hBayesDM package. As the hBayesDM would be used, the data would be fitted by hierarchical Bayesian estimation method.\n",
    "- e.g. `dm_model = 'banditNarm_lapse_decay'`\n",
    "\n",
    "#### 2-2. Target latent process\n",
    "\n",
    "Next, you should decide which latent process to target. Please refer to the list of [available latent process]() for other possible processes and their explanations.\n",
    "- In this example, **prediction error** of chosen options, named as `PEchosen` in hBayesDM, would be a target latent process.\n",
    "- e.g. `process_name = 'PEchosen'`\n",
    "\n",
    "#### 2-3. Check data format of behavioral data.\n",
    "- The data format in `event.tsv` should match with input format of the corresponding model. If not, and you don't want to change your original data, you can use user-defined functions to remap the data while preprocessing. Please refer to `adjust_function`, `adjust_function_dfwise`, `filter_function`, `filter_function_dfwise` in [mbfmri.preprocessing.events module](https://project-model-based-fmri.readthedocs.io/en/latest/mbfmri.preprocessing.html#module-mbfmri.preprocessing.events) ([source code](https://github.com/CCS-Lab/project_model_based_fmri/blob/main/mbfmri/preprocessing/events.py))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Calculated latent process signals using hBayesDM will be saved in a new directory named as `mbmvpa` under `derivatives` directory. As default, `mbmvpa` will be under the same `derivative` folder as the `fmriprep`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing 2 - Generate voxel features <a name = \"VoxelFeatures\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1. ROI mask\n",
    "- Here, an ROI mask is applied to restrict brain regions from which features are retrieved. The following mechanisms are provided to make a mask. \n",
    "    1. Default mask is MNI152 T1 template ([nilearn.datasets.load_mni152_brain_mask](https://nilearn.github.io/modules/generated/nilearn.datasets.load_mni152_brain_mask.html)).\n",
    "    2. You can only include gray matter only by `gm_only` = True. ([nilearn.datasets.fetch_icbm152_brain_gm_mask](https://nilearn.github.io/modules/generated/nilearn.datasets.fetch_icbm152_brain_gm_mask.html)).\n",
    "    3. You can choose ROIs from atlas by `atlas`= *{atlas_name}* and `rois`=*{list of roi}*. Please check available atlases and corresponding ROIs from [link](https://project-model-based-fmri.readthedocs.io/en/latest/roi_info.html#atlas-and-rois).\n",
    "    4. You can provide nii files. The files in *{BIDS_ROOT}/masks/include* and *{BIDS_ROOT}/masks/exclude* will be then binarized by given cut-off threshold,`mask_threshold`. Then the binarized maps in each directory are integrated (Union). The final map can be defined using set operations as \"(map from 1-2-3) $\\cap$ \\[(*include* map) - (*exclude* map)\\].\" You can redirect the mask path (*masks*) by `mask_path` argument.\n",
    "    5. The resulting mask can have reduced resolution by zooming, e.g `zoom`=(2,2,2) will zoom 2mm^3 voxel to 4mm^3. Each dimension on `zoom` corresponds to the rescale factor for each dimension of *xyz* coordinate.\n",
    "\n",
    "- Each of fMRI images will be resampled using the generated ROI mask, producing a flattened vector with shape = (*time*, *feature #*).\n",
    "\n",
    "#### 3-2. Clean bold signal\n",
    "- Additional improvements of the quality of signals are provided like detrending, high-pass filtering etc. The methods are well-established in fMRI analysis literature and please refer to the [document](https://project-model-based-fmri.readthedocs.io/en/latest/mbfmri.preprocessing.html#mbfmri-preprocessing-bold-module) for detail. \n",
    "- Unlike GLM, confounds are controlled in this step by regressing out confound factors. You can designate a list of confound names and each of it should match the corresponding column name in confounds file (generated by prior fMRI preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. fMRI Analysis <a name = \"fMRIAnalysis\"> </a>\n",
    "\n",
    "Choose which method and which model to use for fMRI analysis (GLM, MVPA-ElasticNet, MVPA-MLP, or MVPA-CNN) and decide some details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1. Type of analysis - either GLM or MVPA\n",
    "- MVPA is used as default but GLM could be applied as well.\n",
    "- e.g. `analysis = 'mvpa'` or `analysis = 'glm'`\n",
    "\n",
    "#### 4-2. If you chose MVPA, decide which MVPA model to use and the type of cross-validation.\n",
    "- For MVPA, **ElasticNet** is used as default, but other models such as MLP and CNN are provided by MBfMRI package.\n",
    "    - For fitting ElasticNet, MBfMRI depends on [glmnet Python package](https://github.com/civisanalytics/python-glmnet). You will get plots for lambda searching and coefficients values as the convention of employing ElasticNet.\n",
    "    - e.g. `mvpa_model = 'elasticnet'`, `mvpa_model = 'mlp'`, or `mvpa_model = 'cnn'`\n",
    "\n",
    "\n",
    "- A cross-validation framework is employed in MBfMRI package to secure validity.\n",
    "    - Two options are available currently, \"N-fold\" for N-fold cross-validation and \"N-lnso\" for leave-n-subjects-out. \n",
    "    - You will get the pearson R correlation plot generated using the results of cross-validation. All the visible reports and results are integrated from the results of each fold (you can also locate row result of each fold in the report folder).\n",
    "    - e.g. `method = '5-fold'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run the code! <a name = \"Code\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to run the code!\n",
    "We provide sample codes for the analyses with different types of target latent processes and for different types of fMRI analyses including GLM, MVPA-ElasticNet, MVPA-MPL, and MVPA-CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get started and check the outputs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Example] MVPA - Elastic Net / PE as target latent process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbfmri.core.engine import run_mbfmri\n",
    "\n",
    "_ = run_mbfmri(\n",
    "               ### Identify, load, and save data\n",
    "               bids_layout='mini_bornstein2017',  # the root folder of a BIDS valid dataset\n",
    "               task_name='multiarmedbandit',      # task ID\n",
    "               subjects='all',                    # default: 'all' / could be a list of subject IDs (string) (e.g., ['01', '02'])\n",
    "               sessions='all',                    # default: 'all' / could be a list of sessions. (e.g. ['01','02'])\n",
    "\n",
    "               ### Preprocessing 1 - calculate latent process\n",
    "               dm_model='banditNarm_lapse_decay', # computational model\n",
    "               process_name='PEchosen',           # identifier for target latent process\n",
    "               refit_compmodel=True,              # indicate if refitting comp. model is required\n",
    "               n_core=4,                          # the number of core for multi-processing in hBayesDM    \n",
    "\n",
    "               ### Preprocessing 2 - generate voxel features\n",
    "               feature_name='zoom2rgrout',        # name for indicating preprocessed feature (default: \"unnamed\")\n",
    "               confounds=[\"trans_x\", \"trans_y\",   # list of confounds (including motion regressors)\n",
    "                          \"trans_z\", \"rot_x\",\n",
    "                          \"rot_y\", \"rot_z\"],    \n",
    "               n_thread=4,                        # the number of thread for multi-threading when generating voxel features\n",
    "\n",
    "               ### For fMRI analysis\n",
    "               analysis='mvpa',                   # type of analysis ('mvpa' OR 'glm', default: 'mvpa')\n",
    "               mvpa_model='elasticnet',           # [MVPA] which kind of MVPA model to use ('elasticnet', 'mlp', or 'cnn')\n",
    "               method='5-fold',                   # [MVPA] type of cross-validation\n",
    "    \n",
    "               ### others\n",
    "               overwrite=True,                    # indicate if re-generate voxel feaures and latent process and they should be overwritten. (not related to re-fitting hBayesDM)\n",
    "\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of setting `feature_name`, is to distinguish voxel feature data generated from different configurations and skip redundant preprocessing step when files with the same feature name already exists. For example, by setting `feature_name = \"zoom2rgrout\"`, the preprocessed file will be saved as `sub-01_task-learn_desc-zoom2rgrout_voxelfeature.npy`. But, this argument could be overridden by setting `overwrite = True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Output <a name = \"Output\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brain activation map\n",
    "\n",
    "The final output and the purpose of the MB-MVPA is a brain activation pattern map attributed to the target latent process.<br>\n",
    "This will be obtained by interpreting the MVPA model. For ElasticNet, it means reading coefficients of the linear layer.<br>\n",
    "You can find the nii image under the \"brain_map\" folder in the reports.\n",
    "All the reports will be saved under BIDS_ROOT/derivatives/mbmvpa/mvpa/ (if running glm, last directory will be glm instead of mvpa.)\n",
    "Or, user can redirect the output directory by `report_path={report_path}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Other example codes <a name = \"Examples\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [7-1. MVPA - Elastic Net](#Elasticnet)\n",
    "    * [1) MVPA - Elastic Net / Q value as target latent process](#Elasticnet_Q)\n",
    "    * [2) MVPA - Elastic Net / Model selection](#Elasticnet_modelselection)\n",
    "    * [3) MVPA - Elastic Net /  Use precalculated latent process (Not using hBayesDM)](#Elasticnet_pre)\n",
    "* [7-2. MVPA - MLP](#MLP)\n",
    "* [7-3. MVPA - CNN](#CNN)\n",
    "* [7-4. model-based GLM using MBfMRI](#MBGLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7-1. MVPA - Elastic Net <a name = \"Elasticnet\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) MVPA - Elastic Net / Q value as target latent process <a name = \"Elasticnet_Q\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbfmri.core.engine import run_mbfmri\n",
    "\n",
    "_ = run_mbfmri(\n",
    "               ### Identify, load, and save data\n",
    "               bids_layout='mini_bornstein2017',  # the root folder of a BIDS valid dataset\n",
    "               task_name='multiarmedbandit',      # task ID\n",
    "               subjects='all',                    # default: 'all' / could be a list of subject IDs (string) (e.g., ['01', '02'])\n",
    "               sessions='all',                    # default: 'all' / could be a list of sessions. (e.g. ['01','02'])\n",
    "    \n",
    "               ### Preprocessing 1 - calculate latent process\n",
    "               dm_model='banditNarm_lapse_decay', # computational model\n",
    "               process_name='Qchosen',            # identifier for target latent process\n",
    "               refit_compmodel=True,              # indicate if refitting comp. model is required\n",
    "               n_core=4,                          # the number of core for multi-processing in hBayesDM    \n",
    "\n",
    "               ### Preprocessing 2 - generate voxel features\n",
    "               feature_name='zoom2rgrout',        # name for indicating preprocessed feature (default: \"unnamed\")\n",
    "               confounds=[\"trans_x\", \"trans_y\",   # list of confounds (including motion regressors)\n",
    "                          \"trans_z\", \"rot_x\",\n",
    "                          \"rot_y\", \"rot_z\"],    \n",
    "               n_thread=4,                        # the number of thread for multi-threading when generating voxel features\n",
    "\n",
    "               ### For fMRI analysis\n",
    "               analysis='mvpa',                   # type of analysis ('mvpa' OR 'glm', default: 'mvpa')\n",
    "               mvpa_model='elasticnet',           # [MVPA] which kind of MVPA model to use ('elasticnet', 'mlp', or 'cnn')\n",
    "               method='5-fold',                   # [MVPA] type of cross-validation\n",
    "    \n",
    "               ### others\n",
    "               overwrite=True,                    # indicate if re-generate voxel feaures and latent process and they should be overwritten. (not related to re-fitting hBayesDM)\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) MVPA - Elastic Net / Model selection <a name = \"Elasticnet_modelselection\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbfmri.core.engine import run_mbfmri\n",
    "import hbayesdm\n",
    "\n",
    "_ = run_mbfmri(\n",
    "               ### Identify, load, and save data\n",
    "               bids_layout='mini_bornstein2017',  # the root folder of a BIDS valid dataset\n",
    "               task_name='multiarmedbandit',      # task ID\n",
    "               subjects='all',                    # default: 'all' / could be a list of subject IDs (string) (e.g., ['01', '02'])\n",
    "               sessions='all',                    # default: 'all' / could be a list of sessions. (e.g. ['01','02'])\n",
    "\n",
    "               ### Preprocessing 1 - calculate latent process\n",
    "               dm_model= ['banditNarm_lapse_decay', # computational model candidates\n",
    "                          #'banditNarm_delta',\n",
    "                          'banditNarm_2par_lapse',\n",
    "                          'banditNarm_4par',\n",
    "                          'banditNarm_lapse',\n",
    "                          'banditNarm_singleA_lapse'],\n",
    "               process_name='Qchosen',            # identifier for target latent process\n",
    "               refit_compmodel=True,              # indicate if refitting comp. model is required\n",
    "               n_core=4,                          # the number of core for multi-processing in hBayesDM    \n",
    "\n",
    "               ### Preprocessing 2 - generate voxel features\n",
    "               feature_name='zoom2rgrout',        # name for indicating preprocessed feature (default: \"unnamed\")\n",
    "               confounds=[\"trans_x\", \"trans_y\",   # list of confounds (including motion regressors)\n",
    "                          \"trans_z\", \"rot_x\",\n",
    "                          \"rot_y\", \"rot_z\"],    \n",
    "               n_thread=4,                        # the number of thread for multi-threading when generating voxel features\n",
    "\n",
    "               ### For fMRI analysis\n",
    "               analysis='mvpa',                   # type of analysis ('mvpa' OR 'glm', default: 'mvpa')\n",
    "               mvpa_model='elasticnet',           # [MVPA] which kind of MVPA model to use ('elasticnet', 'mlp', or 'cnn')\n",
    "               method='5-fold',                   # [MVPA] type of cross-validation\n",
    "    \n",
    "               ### others\n",
    "               overwrite=True,                    # indicate if re-generate voxel feaures and latent process and they should be overwritten. (not related to re-fitting hBayesDM)\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) MVPA - Elastic Net /  Use precalculated latent process (Not using hBayesDM)<a name = \"Elasticnet_pre\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbfmri.core.engine import run_mbfmri\n",
    "\n",
    "_ = run_mbfmri(\n",
    "               ### Identify, load, and save data\n",
    "               bids_layout='mini_bornstein2017',  # the root folder of a BIDS valid dataset\n",
    "               task_name='multiarmedbandit',      # task ID\n",
    "               subjects='all',                    # default: 'all' / could be a list of subject IDs (string) (e.g., ['01', '02'])\n",
    "               sessions='all',                    # default: 'all' / could be a list of sessions. (e.g. ['01','02'])\n",
    "    \n",
    "               ### Preprocessing 1 - calculate latent process\n",
    "               skip_compmodel=True,\n",
    "               process_name='PrecalculatedPEchosen',# identifier for target latent process\n",
    "               n_core=4,                            # number of core for multi-processing in hBayesDM    \n",
    "\n",
    "    \n",
    "               ### Preprocessing 2 - generate voxel features\n",
    "               feature_name='zoom2rgrout',        # name for indicating preprocessed feature (default: \"unnamed\")\n",
    "               confounds=[\"trans_x\", \"trans_y\",   # list of confounds (including motion regressors)\n",
    "                          \"trans_z\", \"rot_x\",\n",
    "                          \"rot_y\", \"rot_z\"],    \n",
    "               n_thread=4,                        # the number of thread for multi-threading when generating voxel features\n",
    "\n",
    "               ### For fMRI analysis\n",
    "               analysis='mvpa',                   # type of analysis ('mvpa' OR 'glm', default: 'mvpa')\n",
    "               mvpa_model='elasticnet',           # [MVPA] which kind of MVPA model to use ('elasticnet', 'mlp', or 'cnn')\n",
    "               method='5-fold',                   # [MVPA] type of cross-validation\n",
    "    \n",
    "               ### others\n",
    "               overwrite=True,                    # indicate if re-generate voxel feaures and latent process and they should be overwritten. (not related to re-fitting hBayesDM)\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7-2. MVPA - MLP <a name = \"MLP\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_mbfmri(\n",
    "               ### Identify, load, and save data\n",
    "               bids_layout='mini_bornstein2017',  # the root folder of a BIDS valid dataset\n",
    "               task_name='multiarmedbandit',      # task ID\n",
    "               subjects='all',                    # default: 'all' / could be a list of subject IDs (string) (e.g., ['01', '02'])\n",
    "               sessions='all',                    # default: 'all' / could be a list of sessions. (e.g. ['01','02'])\n",
    "    \n",
    "               ### Preprocessing 1 - calculate latent process\n",
    "               dm_model='banditNarm_lapse_decay', # computational model\n",
    "               process_name='Qchosen',            # identifier for target latent process\n",
    "               refit_compmodel=True,              # indicate if refitting comp. model is required\n",
    "               n_core=4,                          # the number of core for multi-processing in hBayesDM    \n",
    "\n",
    "               ### Preprocessing 2 - generate voxel features\n",
    "               feature_name='zoom2rgrout',        # name for indicating preprocessed feature (default: \"unnamed\")\n",
    "               confounds=[\"trans_x\", \"trans_y\",   # list of confounds (including motion regressors)\n",
    "                          \"trans_z\", \"rot_x\",\n",
    "                          \"rot_y\", \"rot_z\"],    \n",
    "               n_thread=4,                        # the number of thread for multi-threading when generating voxel features\n",
    "\n",
    "               ### For fMRI analysis\n",
    "               analysis='mvpa',                   # type of analysis ('mvpa' OR 'glm', default: 'mvpa')\n",
    "               mvpa_model='mlp',                  # [MVPA] which kind of MVPA model to use ('elasticnet', 'mlp', or 'cnn')\n",
    "               method='5-fold',                   # [MVPA] type of cross-validation\n",
    "    \n",
    "               ### others\n",
    "               overwrite=True,                    # indicate if re-generate voxel feaures and latent process and they should be overwritten. (not related to re-fitting hBayesDM)\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7-3. MVPA - CNN <a name = \"CNN\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_mbfmri(\n",
    "               ### Identify, load, and save data\n",
    "               bids_layout='mini_bornstein2017',  # the root folder of a BIDS valid dataset\n",
    "               task_name='multiarmedbandit',      # task ID\n",
    "               subjects='all',                    # default: 'all' / could be a list of subject IDs (string) (e.g., ['01', '02'])\n",
    "               sessions='all',                    # default: 'all' / could be a list of sessions. (e.g. ['01','02'])\n",
    "    \n",
    "               ### Preprocessing 1 - calculate latent process\n",
    "               dm_model='banditNarm_lapse_decay', # computational model\n",
    "               process_name='Qchosen',            # identifier for target latent process\n",
    "               refit_compmodel=True,              # indicate if refitting comp. model is required\n",
    "               n_core=4,                          # the number of core for multi-processing in hBayesDM    \n",
    "\n",
    "               ### Preprocessing 2 - generate voxel features\n",
    "               feature_name='zoom2rgrout',        # name for indicating preprocessed feature (default: \"unnamed\")\n",
    "               confounds=[\"trans_x\", \"trans_y\",   # list of confounds (including motion regressors)\n",
    "                          \"trans_z\", \"rot_x\",\n",
    "                          \"rot_y\", \"rot_z\"],    \n",
    "               n_thread=4,                        # the number of thread for multi-threading when generating voxel features\n",
    "\n",
    "               ### fMRI analysis\n",
    "               analysis='mvpa',                   # type of analysis ('mvpa' OR 'glm', default: 'mvpa')\n",
    "               mvpa_model='cnn',                  # [MVPA] which kind of MVPA model to use ('elasticnet', 'mlp', or 'cnn')\n",
    "               method='5-fold',                   # [MVPA] type of cross-validation\n",
    "    \n",
    "               ### others\n",
    "               overwrite=True,                    # indicate if re-generate voxel feaures and latent process and they should be overwritten. (not related to re-fitting hBayesDM)\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7-4. model-based GLM using MBfMRI <a name = \"MBGLM\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package provides the GLM approach, model-based GLM, as well and it has the same procedure of the prevailing approach.<br>\n",
    "Following is the tutorial for conducting model-based GLM using MBfMRI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_mbfmri(\n",
    "               ### Identify, load, and save data\n",
    "               bids_layout='mini_bornstein2017',  # the root folder of a BIDS valid dataset\n",
    "               task_name='multiarmedbandit',      # task ID\n",
    "               subjects='all',                    # default: 'all' / could be a list of subject IDs (string) (e.g., ['01', '02'])\n",
    "               sessions='all',                    # default: 'all' / could be a list of sessions. (e.g. ['01','02'])\n",
    "    \n",
    "               ### Preprocessing 1 - calculate latent process\n",
    "               dm_model='banditNarm_lapse_decay', # computational model\n",
    "               process_name='Qchosen',            # identifier for target latent process\n",
    "               refit_compmodel=True,              # indicate if refitting comp. model is required\n",
    "               n_core=4,                          # the number of core for multi-processing in hBayesDM    \n",
    "\n",
    "               ### Preprocessing 2 - generate voxel features\n",
    "               feature_name='zoom2rgrout',        # name for indicating preprocessed feature (default: \"unnamed\")\n",
    "               n_thread=4,                        # the number of thread for multi-threading when generating voxel features\n",
    "\n",
    "               ### fMRI analysis\n",
    "               analysis='glm',                    # type of analysis ('mvpa' OR 'glm', default: 'mvpa')\n",
    "               confounds=[\"trans_x\", \"trans_y\",   # list of confounds to be in desgin matrix (including motion regressors)\n",
    "                          \"trans_z\", \"rot_x\",\n",
    "                          \"rot_y\", \"rot_z\"],    \n",
    "               ### others\n",
    "               overwrite=True,                    # indicate if re-generate voxel feaures and latent process and they should be overwritten. (not related to re-fitting hBayesDM)\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
