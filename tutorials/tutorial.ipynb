{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: model-based MVPA using MBfMRI\n",
    "\n",
    "This tutorial is for offering guidance to perform model-based MVPA using MBfMRI package.<br>\n",
    "By using this package, users can conduct the analysis with few lines of codes.<br>\n",
    "You only need to prepare a root path for task-based fMRI data the preprocessed images under the path.\n",
    "\n",
    "For model-based GLM using MBfMRI, see [here](#MBGLM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow of MVPA approach, model-based MVPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact workflow of the model-based MVPA consists of the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=https://raw.githubusercontent.com/CCS-Lab/project_model_based_fmri/main/images/mbmvpa_workflow.png width=\"800px\"><\\center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Generate latent process signals** by fitting computational models with behavioral data and extracting time-series of latent process followed by HRF convolution.\n",
    "\n",
    "2. **Generate multi-voxel signals** from preprocess fMRI images by allowing ROI masking, zooming spatial resolution, and improving the quality of signals by several well-established methods (e.g. detrending, high-pass filtering, regressing out confounds).\n",
    "\n",
    "3. **Train MVPA models** by feeding multi-voxel signals as input (X) and latent process signals as ouput (y), or target, employing the repeated cross-validation framework. \n",
    "\n",
    "4. **Interpret the trained MVPA models** to visualize the brain implementation of the target latent process quantified as brain activation pattern attributed  to predict the target signals from the multi-voxel signals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aforementioned procedures can be done by a single function, `mbfmri.core.engine.run_mbfmri`.<br>\n",
    "Users can choose which kinds of approach to apply and latent processes of interest.<br>\n",
    "The configuration of the analysis can be controlled by various arguments.<br>\n",
    "Users can manipulate each of the setting by providing relevant keywarded argument (e.g. run_mbfmri(..., mvpa_model='mlp',...) or run_mbfmri(...,detrend=True)).\n",
    "```python\n",
    "from mbfmri.core.engine import run_mbfmri\n",
    "\n",
    "_ = run_mbfmri(bids_layout='mini_bornstein2017',    # data path - the root for entire BIDS layout \n",
    "               task_name='multiarmedbandit',        # identifier for task (BIDS))\n",
    "               dm_model= 'banditNarm_lapse_decay',  # computational model\n",
    "               process_name='PEchosen'              # identifier for target latent process\n",
    "               \n",
    "               ##################################################################################\n",
    "               #                                                                                #\n",
    "               #                ANY KEYWARDED ARGUMENT DEFINED IN CONFIGURATION                 #\n",
    "               #                                                                                #\n",
    "               ##################################################################################\n",
    "               )\n",
    "```\n",
    "\n",
    "Please refer to the [document](https://project-model-based-fmri.readthedocs.io/en/latest/mbfmri.core.html#mbfmri-core-engine-run-mbfmri) for the full list of configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Example data]\n",
    "\n",
    "The example data is a mini-size version of the dataset issued by Bornstein et al., 2017 ([paper](https://www.nature.com/articles/nn.4573#abstracthttps://www.nature.com/articles/nn.4573#abstract), [openneuro](https://openneuro.org/datasets/ds001607/versions/1.0.1)).<br>\n",
    "The data includes 8 subjects and each of them has one run for Reinforcement Learning task with 180 trials. <br>\n",
    "You can download the zip file from the [link]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "bids_layout = \"mini_bornstein2017\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you should do before running MBfMRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1. Data - Check input data](#Data)\n",
    "#### [2. Preprocessing 1 - Calculate latent process](#LatentProcess)\n",
    "#### [3. Preprocessing 2 - Generate voxel features](#VoxelFeatures)\n",
    "#### [4. fMRI Analysis - Choose which method and which model to use for fMRI analysis and decide some details](fMRIAnalysis)\n",
    "#### [5. Run the code!](#Code)\n",
    "#### [6. Output](#Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data - Check input data <a name = \"Data\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1. BIDS layout with original data\n",
    "\n",
    "The original task-based fMRI data should be in `bids_layout`.<br> \n",
    "Also, you need to place preprocessed fMRI images under the *derivatives* folder under `bids_layout`, named as `fmriprep`.<br>\n",
    "(In the original layoout of sample data, there are only events files as the preprocessed images will be used.)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_description.json  masks   sub-02  sub-04  sub-06  sub-08\n",
      "derivatives\t\t  sub-01  sub-03  sub-05  sub-07\n"
     ]
    }
   ],
   "source": [
    "# Check bids layout in the root\n",
    "!ls mini_bornstein2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The behavioral data should be in `events.tsv`, following the original BIDS layout as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>type</th>\n",
       "      <th>choice</th>\n",
       "      <th>rwdval</th>\n",
       "      <th>RT</th>\n",
       "      <th>time_feedback</th>\n",
       "      <th>gain</th>\n",
       "      <th>loss</th>\n",
       "      <th>PrecalculatedQchosen</th>\n",
       "      <th>PrecalculatedPEchosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.320</td>\n",
       "      <td>3</td>\n",
       "      <td>bandit</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2439</td>\n",
       "      <td>11.5639</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15.303</td>\n",
       "      <td>3</td>\n",
       "      <td>bandit</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7019</td>\n",
       "      <td>18.0049</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.897044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22.286</td>\n",
       "      <td>3</td>\n",
       "      <td>bandit</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>25.2511</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>29.269</td>\n",
       "      <td>3</td>\n",
       "      <td>bandit</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0103</td>\n",
       "      <td>32.2793</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.897044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>36.253</td>\n",
       "      <td>3</td>\n",
       "      <td>bandit</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4705</td>\n",
       "      <td>38.7235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.733677</td>\n",
       "      <td>-0.733677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   onset  duration    type  choice  rwdval      RT  \\\n",
       "0           0   8.320         3  bandit       1       0  1.2439   \n",
       "1           1  15.303         3  bandit       2      10  0.7019   \n",
       "2           2  22.286         3  bandit       3       0  0.9651   \n",
       "3           3  29.269         3  bandit       3      10  1.0103   \n",
       "4           4  36.253         3  bandit       2       0  0.4705   \n",
       "\n",
       "   time_feedback  gain  loss  PrecalculatedQchosen  PrecalculatedPEchosen  \n",
       "0        11.5639     0     0              0.000000               0.000000  \n",
       "1        18.0049    10     0              0.000000               4.897044  \n",
       "2        25.2511     0     0              0.000000               0.000000  \n",
       "3        32.2793    10     0              0.000000               4.897044  \n",
       "4        38.7235     0     0              0.733677              -0.733677  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check behavioral data\n",
    "import pandas as pd\n",
    "pd.read_table('mini_bornstein2017/sub-01/func/sub-01_task-multiarmedbandit_events.tsv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. Derivative layout from *fMRIPrep*\n",
    "\n",
    "The package assumes that preprocessing images is done by [fMRIPrep](https://fmriprep.org/en/stable/). <br>\n",
    "Please refer to [mbfmri/utils/config.py](https://github.com/CCS-Lab/project_model_based_fmri/blob/main/mbfmri/utils/config.py) for configuration of it.<br> \n",
    "\n",
    "If you preprocessed fMRI data using other tool than fMRIPrep, you should change the directory and file layout to apply MBfMRI package to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls mini_bornstein2017/derivatives/fmriprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls mini_bornstein2017/derivatives/fmriprep/sub-01/func/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-3. Mask images\n",
    "\n",
    "The mask images would be located under the folder below as default `(BIDSroot/masks/include)`.<br>\n",
    "The images here are integrated into one binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls mini_bornstein2017/masks/include\n",
    "# [??] what should I do if I want to use other mask images?\n",
    "# [CJ] Maybe we should discuss through Zoom about this. \n",
    "#      I am looking for appropriate and easy explanation for this function.\n",
    "#      It might be better to refer to \"_build_mask\" function codes located in\n",
    "#      mbfmri/utils/bold_utils.py. The mechanism is quite straightforward.\n",
    "# [??] And what's the purpose of this mask images?\n",
    "# [CJ] One of the major purposes is reducing the number of features (which is not applicable in CNN),\n",
    "#      and another would be to restrict regions which are supposed be included or excluded in MVPA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing 1 - Caculate latent process: Choose cognitive model and target latent process to analyze in hBayesDM (or prepare precaculated latent process) <a name = \"LatentProcess\"> </a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1. hBayesDM model - Now you need to choose which cognitive model to use. Please refer to [hBayesDM](https://hbayesdm.readthedocs.io/en/v1.0.1/models.html) and check available models.<br>\n",
    "- Here, the task used in the example data could be categorized as a **multi-armed bandit task** which requires subjects to learn the probability of three cards (or bandits) by rewards or none. So **a reinforcement learning model for multi-armed bandit task with 5 parameter (including decision noise and decay rate but not choice perseveration)** ([Niv et al., 2015](https://www.jneurosci.org/content/35/21/8145)) is chosen here for the example data. The model is named as `banditNarm_lapse_decay` in the hBayesDM package. As the hBayesDM would be used, the data would be fitted by hierarchical Bayesian estimation method.\n",
    "- e.g. `dm_model = 'banditNarm_lapse_decay'`\n",
    "\n",
    "#### 2-2. Target latent process - Next, you should decide which latent process to target. Please refer to the list of [available latent process]() for other possible processes and their explanations.\n",
    "- In this example, **prediction error** of chosen options, named as `PEchosen` in hBayesDM, would be a target latent process.\n",
    "- e.g. `process_name = 'PEchosen'`\n",
    "\n",
    "#### 2-3. Check data format of behavioral data.\n",
    "- The data format in `event.tsv` should match with input format of the corresponding model. If not, and you don't want to change your original data, you can use user-defined functions to remap the data while preprocessing. Please refer to `adjust_function`, `adjust_function_dfwise`, `filter_function`, `filter_function_dfwise` in [mbfmri.preprocessing.events module](https://project-model-based-fmri.readthedocs.io/en/latest/mbfmri.preprocessing.html#module-mbfmri.preprocessing.events) ([source code](https://github.com/CCS-Lab/project_model_based_fmri/blob/main/mbfmri/preprocessing/events.py))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Calculated latent process signals using hBayesDM will be saved in a new directory named as `mbmvpa` under `derivatives` directory. As default, `mbmvpa` will be under the same `derivative` folder as the `fmriprep`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing 2 - Generate voxel features <a name = \"VoxelFeatures\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1. ROI mask\n",
    "- Here, an ROI mask is applied to restrict brain regions from which features are retrieved. The following mechanisms are provided to make a mask. \n",
    "    1. Default mask is MNI152 T1 template ([nilearn.datasets.load_mni152_brain_mask](https://nilearn.github.io/modules/generated/nilearn.datasets.load_mni152_brain_mask.html)).\n",
    "    2. You can only include gray matter only by `gm_only` = True. ([nilearn.datasets.fetch_icbm152_brain_gm_mask](https://nilearn.github.io/modules/generated/nilearn.datasets.fetch_icbm152_brain_gm_mask.html)).\n",
    "    3. You can choose ROIs from atlas by `atlas`= *{atlas_name}* and `rois`=*{list of roi}*. Please check available atlases and corresponding ROIs from [link](https://project-model-based-fmri.readthedocs.io/en/latest/roi_info.html#atlas-and-rois).\n",
    "    4. You can provide nii files. The files in *{BIDS_ROOT}/masks/include* and *{BIDS_ROOT}/masks/exclude* will be then binarized by given cut-off threshold,`mask_threshold`. Then the binarized maps in each directory are integrated (Union). The final map can be defined using set operations as \"(map from 1-2-3) $\\cap$ \\[(*include* map) - (*exclude* map)\\].\" You can redirect the mask path (*masks*) by `mask_path` argument.\n",
    "    5. The resulting mask can have reduced resolution by zooming, e.g `zoom`=(2,2,2) will zoom 2mm^3 voxel to 4mm^3. Each dimension on `zoom` corresponds to the rescale factor for each dimension of *xyz* coordinate.\n",
    "\n",
    "- Each of fMRI images will be resampled using the generated ROI mask, producing a flattened vector with shape = (*time*, *feature #*).\n",
    "\n",
    "#### 3-2. Clean bold signal\n",
    "- Additional improvements of the quality of signals are provided like detrending, high-pass filtering etc. The methods are well-established in fMRI analysis literature and please refer to the [document](https://project-model-based-fmri.readthedocs.io/en/latest/mbfmri.preprocessing.html#mbfmri-preprocessing-bold-module) for detail. \n",
    "- Unlike GLM, confounds are controlled in this step by regressing out confound factors. You can designate a list of confound names and each of it should match the corresponding column name in confounds file (generated by prior fMRI preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. fMRI Analysis - Choose which method and which model to use for fMRI analysis (GLM, MVPA-ElasticNet, MVPA-MLP, or MVPA-CNN) and decide some details <a name = \"fMRIAnalysis\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-1. Type of analysis - either GLM or MVPA\n",
    "- MVPA is used as default but GLM could be applied as well.\n",
    "- e.g. `analysis = 'mvpa'` or `analysis = 'glm'`\n",
    "\n",
    "#### 4-2. If you chose MVPA, you should decide which MVPA model to use and the type of cross-validation.\n",
    "- For MVPA, **ElasticNet** is used as default, but other models such as MLP and CNN are provided by MBfMRI package.\n",
    "    - For fitting ElasticNet, MBfMRI depends on [glmnet Python package](https://github.com/civisanalytics/python-glmnet). You will get plots for lambda searching and coefficients values as the convention of employing ElasticNet.\n",
    "    - e.g. `mvpa_model = 'elasticnet'`, `mvpa_model = 'mlp'`, or `mvpa_model = 'cnn'`\n",
    "\n",
    "\n",
    "- A cross-validation framework is employed in MBfMRI package to secure validity.\n",
    "    - Two options are available currently, \"N-fold\" for N-fold cross-validation and \"N-lnso\" for leave-n-subjects-out. \n",
    "    - You will get the pearson R correlation plot generated using the results of cross-validation. All the visible reports and results are integrated from the results of each fold (you can also locate row result of each fold in the report folder).\n",
    "    - e.g. `method = '5-fold'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run the code! <a name = \"Code\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to run the code!\n",
    "We provide sample codes for the analyses with different types of target latent processes and for different types of fMRI analyses including GLM, MVPA-ElasticNet, MVPA-MPL, and MVPA-CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Output <a name = \"Output\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brain activation map\n",
    "\n",
    "The final output and the purpose of the MB-MVPA is a brain activation pattern map attributed to the target latent process.<br>\n",
    "This will be obtained by interpreting the MVPA model. For ElasticNet, it means reading coefficients of the linear layer.<br>\n",
    "You can find the nii image under the \"brain_map\" folder in the reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get started and check the outputs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) MVPA - Elastic NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1) MVPA - Elastic Net / PE as target latent process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbfmri.core.engine import run_mbfmri\n",
    "\n",
    "_ = run_mbfmri(\n",
    "               ### To identify, load, and save data\n",
    "               bids_layout='mini_bornstein2017',    # data path - the root for entire BIDS layout \n",
    "               task_name='multiarmedbandit',        # identifier for task (BIDS)\n",
    "               subjects='all',                      # default: 'all' - load all subjects in the layout.\n",
    "                                                      # could be a list of subject IDs (string) (e.g., ['01', '02'])\n",
    "               sessions = 'all',                    # default: 'all', could be a list of sessions. (e.g. ['01','02'])\n",
    "               \n",
    "               feature_name='zoom2rgrout',          # Name for indicating preprocessed feature (default: \"unnamed\") - to distinguish voxel feature data generated from different configurations.\n",
    "                                                      # (e.g. the preprocessed file will be saved as: \"sub-01_task-learn_desc-zoom2rgrout_voxelfeature.npy\" ) \n",
    "                                                      # Redundant preprocessing step could be skipped and avoided when the files with the same feature name already exists.\n",
    "                                                      # But it could be overridden by setting \"overwrite = True\"\n",
    "    \n",
    "\n",
    "               confounds=[\"trans_x\", \"trans_y\",     # list of confounds (including motion regressors)\n",
    "                          \"trans_z\", \"rot_x\",\n",
    "                          \"rot_y\", \"rot_z\"],    \n",
    "    \n",
    "               ### To run computational modeling (use hBayesDM) and make latent process signal\n",
    "               dm_model= 'banditNarm_lapse_decay',  # computational model\n",
    "               process_name='PEchosen',             # identifier for target latent process\n",
    "               refit_compmodel=True,                # indicate if refitting comp. model is required\n",
    "               n_core=4,                            # number of core for multi-processing in hBayesDM    \n",
    "\n",
    "    \n",
    "               ### For fMRI analysis\n",
    "               analysis='mvpa',                     # name of analysis ('mvpa' or 'glm', default: 'mvpa')\n",
    "               mvpa_model='elasticnet',             # (ONLY for MVPA) which kind of MVPA model will be used ('elasticnet', 'mlp', or 'cnn')\n",
    "               method='5-fold',                     # (ONLY for MVPA) type of cross-validation\n",
    "\n",
    "               n_thread=4,                          # number of thread for multi-threading in generating voxel features\n",
    "               \n",
    "    \n",
    "               ### others\n",
    "               overwrite=True,                      # indicate if re-generate voxel feaures and latent process and they should be overwritten. (not related to re-fitting hBayesDM)\n",
    "\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2) MVPA - Elastic Net / Q value as target latent process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbfmri.core.engine import run_mbfmri\n",
    "\n",
    "_ = run_mbfmri(\n",
    "               # To identify, load, and save data\n",
    "               bids_layout='mini_bornstein2017',    # data path - the root for entire BIDS layout \n",
    "               task_name='multiarmedbandit',        # identifier for task (BIDS)\n",
    "               subjects='all',                      # default: 'all' - load all subjects in the layout.\n",
    "                                                      # could be a list of subject IDs (string) (e.g., ['01', '02'])\n",
    "               sessions = 'all',                    # default: 'all', could be a list of sessions. (e.g. ['01','02'])\n",
    "               feature_name='zoom2rgrout',          # Name for indicating preprocessed feature (default: \"unnamed\")\n",
    "\n",
    "    \n",
    "               # To run computational modeling (use hBayesDM) and make latent process signal\n",
    "               dm_model= 'banditNarm_lapse_decay',  # computational model\n",
    "               process_name='Qchosen',              # identifier for target latent process\n",
    "               refit_compmodel=True,                # indicate if refitting comp. model is required\n",
    "               n_core=4,                            # number of core for multi-processing in hBayesDM    \n",
    "\n",
    "    \n",
    "               # For fMRI analysis\n",
    "               analysis='mvpa',                     # name of analysis ('mvpa' or 'glm', default: 'mvpa')\n",
    "               mvpa_model='elasticnet',             # (ONLY for MVPA) which kind of MVPA model will be used ('elasticnet', 'mlp', or 'cnn')\n",
    "               method='5-fold',                     # (ONLY for MVPA) type of cross-validation\n",
    "               confounds=[\"trans_x\", \"trans_y\",     # list of confounds to regress out (including motion regressors)\n",
    "                          \"trans_z\", \"rot_x\",\n",
    "                          \"rot_y\", \"rot_z\"],    \n",
    "               n_thread=4,                          # number of thread for multi-threading in generating voxel features\n",
    "               \n",
    "    \n",
    "               # others\n",
    "               overwrite=True,                      # indicate if re-run and overwriting are required \n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-3) MVPA - Elastic Net / Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbfmri.core.engine import run_mbfmri\n",
    "import hbayesdm\n",
    "\n",
    "_ = run_mbfmri(\n",
    "               # To identify, load, and save data\n",
    "               bids_layout='mini_bornstein2017',    # data path - the root for entire BIDS layout \n",
    "               task_name='multiarmedbandit',        # identifier for task (BIDS)\n",
    "               subjects='all',                      # default: 'all' - load all subjects in the layout.\n",
    "                                                      # could be a list of subject IDs (string) (e.g., ['01', '02'])\n",
    "               sessions = 'all',                    # default: 'all', could be a list of sessions. (e.g. ['01','02'])s\n",
    "               feature_name='zoom2rgrout',          # Name for indicating preprocessed feature (default: \"unnamed\")\n",
    "\n",
    "    \n",
    "               # To run computational modeling (use hBayesDM) and make latent process signal\n",
    "               dm_model= ['banditNarm_lapse_decay', # computational model candidates\n",
    "                          #'banditNarm_delta',\n",
    "                          'banditNarm_2par_lapse',\n",
    "                          'banditNarm_4par',\n",
    "                          'banditNarm_lapse',\n",
    "                          'banditNarm_singleA_lapse'],\n",
    "               process_name='Qchosen',              # identifier for target latent process\n",
    "               refit_compmodel=True,                # indicate if refitting comp. model is required\n",
    "               n_core=4,                            # number of core for multi-processing in hBayesDM    \n",
    "\n",
    "    \n",
    "               # For fMRI analysis\n",
    "               analysis='mvpa',                     # name of analysis ('mvpa' or 'glm', default: 'mvpa')\n",
    "               mvpa_model='elasticnet',             # (ONLY for MVPA) which kind of MVPA model will be used ('elasticnet', 'mlp', or 'cnn')\n",
    "               method='5-fold',                     # (ONLY for MVPA) type of cross-validation\n",
    "               confounds=[\"trans_x\", \"trans_y\",     # list of confounds to regress out (including motion regressors)\n",
    "                          \"trans_z\", \"rot_x\",\n",
    "                          \"rot_y\", \"rot_z\"],    \n",
    "               n_thread=4,                          # number of thread for multi-threading in generating voxel features\n",
    "               \n",
    "    \n",
    "               # others\n",
    "               overwrite=True,                      # indicate if re-run and overwriting are required \n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-4) MVPA - Elastic Net /  Use precalculated latent process (Not using hBayesDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbfmri.core.engine import run_mbfmri\n",
    "\n",
    "_ = run_mbfmri(\n",
    "               # To identify, load, and save data\n",
    "               bids_layout='mini_bornstein2017',    # data path - the root for entire BIDS layout \n",
    "               task_name='multiarmedbandit',        # identifier for task (BIDS)\n",
    "               subjects='all',                      # default: 'all' - load all subjects in the layout.\n",
    "                                                      # could be a list of subject IDs (string) (e.g., ['01', '02'])\n",
    "               sessions = 'all',                    # default: 'all', could be a list of sessions. (e.g. ['01','02'])\n",
    "               feature_name='zoom2rgrout',          # Name for indicating preprocessed feature (default: \"unnamed\")\n",
    "\n",
    "    \n",
    "               # To run computational modeling (use hBayesDM) and make latent process signal\n",
    "               skip_compmodel=True,\n",
    "               process_name='PrecalculatedPEchosen',# identifier for target latent process\n",
    "               n_core=4,                            # number of core for multi-processing in hBayesDM    \n",
    "\n",
    "    \n",
    "               # For fMRI analysis\n",
    "               analysis='mvpa',                     # name of analysis ('mvpa' or 'glm', default: 'mvpa')\n",
    "               mvpa_model='elasticnet',             # (ONLY for MVPA) which kind of MVPA model will be used ('elasticnet', 'mlp', or 'cnn')\n",
    "               method='5-fold',                     # (ONLY for MVPA) type of cross-validation\n",
    "               confounds=[\"trans_x\", \"trans_y\",     # list of confounds to regress out (including motion regressors)\n",
    "                          \"trans_z\", \"rot_x\",\n",
    "                          \"rot_y\", \"rot_z\"],    \n",
    "               n_thread=4,                          # number of thread for multi-threading in generating voxel features\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) MVPA - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_mbfmri(\n",
    "               # To identify, load, and save data\n",
    "               bids_layout='mini_bornstein2017',    # data path - the root for entire BIDS layout \n",
    "               task_name='multiarmedbandit',        # identifier for task (BIDS)\n",
    "               subjects='all',                      # default: 'all' - load all subjects in the layout.\n",
    "                                                      # could be a list of subject IDs (string) (e.g., ['01', '02'])\n",
    "               sessions = 'all',                    # default: 'all', could be a list of sessions. (e.g. ['01','02'])\n",
    "               feature_name='zoom2rgrout',          # Name for indicating preprocessed feature (default: \"unnamed\")\n",
    "\n",
    "    \n",
    "               # To run computational modeling (use hBayesDM) and make latent process signal\n",
    "               dm_model= 'banditNarm_lapse_decay',  # computational model\n",
    "               process_name='Qchosen',             # identifier for target latent process\n",
    "               refit_compmodel=True,                # indicate if refitting comp. model is required\n",
    "               n_core=4,                            # number of core for multi-processing in hBayesDM    \n",
    "\n",
    "    \n",
    "               # For fMRI analysis\n",
    "               analysis='mvpa',                     # name of analysis ('mvpa' or 'glm', default: 'mvpa')\n",
    "               mvpa_model='mlp',                    # (ONLY for MVPA) which kind of MVPA model will be used ('elasticnet', 'mlp', or 'cnn')\n",
    "               method='5-fold',                     # (ONLY for MVPA) type of cross-validation\n",
    "               confounds=[\"trans_x\", \"trans_y\",     # list of confounds to regress out (including motion regressors)\n",
    "                          \"trans_z\", \"rot_x\",\n",
    "                          \"rot_y\", \"rot_z\"],    \n",
    "               n_thread=4,                          # number of thread for multi-threading in generating voxel features\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) MVPA - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_mbfmri(\n",
    "               # To identify, load, and save data\n",
    "               bids_layout='mini_bornstein2017',    # data path - the root for entire BIDS layout \n",
    "               task_name='multiarmedbandit',        # identifier for task (BIDS)\n",
    "               subjects='all',                      # default: 'all' - load all subjects in the layout.\n",
    "                                                      # could be a list of subject IDs (string) (e.g., ['01', '02'])\n",
    "               sessions = 'all',                    # default: 'all', could be a list of sessions. (e.g. ['01','02'])\n",
    "               feature_name='zoom2rgrout',          # Name for indicating preprocessed feature (default: \"unnamed\")\n",
    "\n",
    "\n",
    "    \n",
    "               # To run computational modeling (use hBayesDM) and make latent process signal\n",
    "               dm_model= 'banditNarm_lapse_decay',  # computational model\n",
    "               process_name='Qchosen',             # identifier for target latent process\n",
    "               refit_compmodel=True,                # indicate if refitting comp. model is required\n",
    "               n_core=4,                            # number of core for multi-processing in hBayesDM    \n",
    "\n",
    "    \n",
    "               # For fMRI analysis\n",
    "               analysis='mvpa',                     # name of analysis ('mvpa' or 'glm', default: 'mvpa')\n",
    "               mvpa_model='cnn',                    # (ONLY for MVPA) which kind of MVPA model will be used ('elasticnet', 'mlp', or 'cnn')\n",
    "               method='5-fold',                     # (ONLY for MVPA) type of cross-validation\n",
    "               confounds=[\"trans_x\", \"trans_y\",     # list of confounds to regress out (including motion regressors)\n",
    "                          \"trans_z\", \"rot_x\",\n",
    "                          \"rot_y\", \"rot_z\"],    \n",
    "               n_thread=4,                          # number of thread for multi-threading in generating voxel features\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: model-based GLM using MBfMRI <a name = \"MBGLM\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package provides the GLM approach, model-based GLM, as well and it has the same procedure of the prevailing approach.<br>\n",
    "Following is the tutorial for conducting model-based GLM using MBfMRI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = run_mbfmri(\n",
    "               # To identify, load, and save data\n",
    "               bids_layout='mini_bornstein2017',    # data path - the root for entire BIDS layout \n",
    "               task_name='multiarmedbandit',        # identifier for task (BIDS)\n",
    "               subjects='all',                      # default: 'all' - load all subjects in the layout.\n",
    "                                                      # could be a list of subject IDs (string) (e.g., ['01', '02'])\n",
    "               sessions = 'all',                    # default: 'all', could be a list of sessions. (e.g. ['01','02'])\n",
    "               \n",
    "               # To run computational modeling (use hBayesDM) and make latent process signal\n",
    "               dm_model= 'banditNarm_lapse_decay',  # computational model\n",
    "               process_name='Qchosen',             # identifier for target latent process\n",
    "               refit_compmodel=True,                # indicate if refitting comp. model is required\n",
    "               n_core=4,                            # number of core for multi-processing in hBayesDM    \n",
    "\n",
    "    \n",
    "               # For fMRI analysis\n",
    "               analysis='glm',                      # name of analysis ('mvpa' or 'glm', default: 'mvpa')\n",
    "               confounds=[\"trans_x\", \"trans_y\",     # list of confounds to be in desgin matrix (including motion regressors)\n",
    "                          \"trans_z\", \"rot_x\",\n",
    "                          \"rot_y\", \"rot_z\"],    \n",
    "               n_thread=4,                          # number of thread for multi-threading in generating voxel features & Firstlevel glm\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
