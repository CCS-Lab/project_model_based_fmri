{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import first_level_from_bids\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bids import BIDSLayout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheoljun/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/bids/layout/models.py:152: FutureWarning: The 'extension' entity currently excludes the leading dot ('.'). As of version 0.14.0, it will include the leading dot. To suppress this warning and include the leading dot, use `bids.config.set_option('extension_initial_dot', True)`.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "layout =  BIDSLayout(\"tutorial_data/ccsl_prl\",derivatives=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(Path('.'),Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'prl'\n",
    "space_name = 'MNI152NLin2009cAsym'\n",
    "smoothing_fwhm = 6.0\n",
    "confounds = ['trans_x','trans_y','trans_z','rot_x', 'rot_y', 'rot_z']\n",
    "process_name = 'PEchosen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbmvpa_layout = layout.derivatives['MB-MVPA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheoljun/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py:853: UserWarning: SliceTimingRef not found in file /home/cheoljun/project_model_based_fmri/tutorials/tutorial_data/ccsl_prl/derivatives/fmriprep/sub-01/ses-01/func/sub-01_ses-01_task-prl_run-01_space-MNI152NLin2009cAsym_desc-preproc_bold.json. It will be assumed that the slice timing reference is 0.0 percent of the repetition time. If it is not the case it will need to be set manually in the generated list of models\n",
      "  img_specs[0])\n"
     ]
    }
   ],
   "source": [
    "models, models_run_imgs, \\\n",
    "            models_events, models_confounds = first_level_from_bids(layout.root,\n",
    "                                                                    task_name,\n",
    "                                                                    space_name,\n",
    "                                                                    smoothing_fwhm=smoothing_fwhm,\n",
    "                                                                    derivatives_folder=layout.derivatives['fMRIPrep'].root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models_confounds)):\n",
    "    for j in range(len(models_confounds[i])):\n",
    "        mc = models_confounds[i][j]\n",
    "        mc = mc[confounds]\n",
    "        models_confounds[i][j] = mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity(img_path):\n",
    "    filename = Path(img_path).stem\n",
    "    entity = {}\n",
    "    for z in filename.split('_'):\n",
    "        if '-' in z:\n",
    "            key,val = z.split('-')\n",
    "            entity[key] = val\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models_run_imgs)):\n",
    "    \n",
    "    for j in range(len(models_run_imgs[i])):\n",
    "        entity = get_entity(models_run_imgs[i][j])\n",
    "        kwargs = {}\n",
    "        if 'ses' in entity.keys():\n",
    "            kwargs['session'] = entity['ses']\n",
    "        if 'run' in entity.keys():\n",
    "            kwargs['run'] = entity['run']\n",
    "        kwargs['subject'] = entity['sub']\n",
    "\n",
    "        kwargs['task'] = task_name\n",
    "        kwargs['desc'] = process_name\n",
    "        kwargs['suffix'] = 'modulation'\n",
    "        md = mbmvpa_layout.get(**kwargs)[0]\n",
    "        md = pd.read_table(md)\n",
    "        md['trial_type'] = [process_name]*len(md)\n",
    "        models_events[i][j] = md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/home/cheoljun/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/nilearn/glm/first_level/experimental_paradigm.py:63: UserWarning: 'modulation' column found in the given events data.\n",
      "  warnings.warn(\"'modulation' column found in the given events data.\")\n",
      "/home/cheoljun/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/nilearn/glm/first_level/experimental_paradigm.py:63: UserWarning: 'modulation' column found in the given events data.\n",
      "  warnings.warn(\"'modulation' column found in the given events data.\")\n",
      " 50%|█████     | 1/2 [02:16<02:16, 136.93s/it]/home/cheoljun/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/nilearn/glm/first_level/experimental_paradigm.py:63: UserWarning: 'modulation' column found in the given events data.\n",
      "  warnings.warn(\"'modulation' column found in the given events data.\")\n",
      "/home/cheoljun/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/nilearn/glm/first_level/experimental_paradigm.py:63: UserWarning: 'modulation' column found in the given events data.\n",
      "  warnings.warn(\"'modulation' column found in the given events data.\")\n",
      "100%|██████████| 2/2 [04:23<00:00, 131.57s/it]\n"
     ]
    }
   ],
   "source": [
    "first_level_models = [models[i].fit([nib.load(run_img) for run_img in models_run_imgs[i]], events=models_events[i], confounds=models_confounds[i]) \\\n",
    "                          for i in tqdm(range(len(models)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FirstLevelModel(signal_scaling=True, smoothing_fwhm=6.0, subject_label='01',\n",
       "                t_r=1.5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_level_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_design_matrix' from 'nilearn.reporting' (/home/cheoljun/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/nilearn/reporting/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ebbccb270ee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnilearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreporting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_design_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_design_matrix' from 'nilearn.reporting' (/home/cheoljun/.cache/pypoetry/virtualenvs/model-based-fmri-A7ELC43w-py3.7/lib/python3.7/site-packages/nilearn/reporting/__init__.py)"
     ]
    }
   ],
   "source": [
    "from nilearn.reporting import plot_design_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level_model = first_level_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(first_level_model.design_matrices_[i].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_def = [np.zeros( len(dm.columns)) for dm in first_level_model.design_matrices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, dm in enumerate(first_level_model.design_matrices_):\n",
    "    contrast_def[i][dm.columns.get_loc(process_name)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_def  = [1] + [0] * (n_col-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_def = [ np.array([1] + [0]*(17-1)),np.array([1] + [0]*(17-1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_map = first_level_model.compute_contrast(contrast_def=contrast_def, output_type='z_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FirstLevelModel(signal_scaling=True, smoothing_fwhm=6.0, subject_label='01',\n",
       "                t_r=1.5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_level_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_level_models[0].subject_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_cache',\n",
       " '_check_n_features',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_get_voxelwise_model_attribute',\n",
       " '_more_tags',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_validate_data',\n",
       " 'compute_contrast',\n",
       " 'design_matrices_',\n",
       " 'drift_model',\n",
       " 'drift_order',\n",
       " 'fir_delays',\n",
       " 'fit',\n",
       " 'fit_transform',\n",
       " 'generate_report',\n",
       " 'get_params',\n",
       " 'high_pass',\n",
       " 'hrf_model',\n",
       " 'labels_',\n",
       " 'mask_img',\n",
       " 'masker_',\n",
       " 'memory',\n",
       " 'memory_level',\n",
       " 'min_onset',\n",
       " 'minimize_memory',\n",
       " 'n_jobs',\n",
       " 'noise_model',\n",
       " 'predicted',\n",
       " 'r_square',\n",
       " 'residuals',\n",
       " 'results_',\n",
       " 'scaling_axis',\n",
       " 'set_params',\n",
       " 'signal_scaling',\n",
       " 'slice_time_ref',\n",
       " 'smoothing_fwhm',\n",
       " 'standardize',\n",
       " 'subject_label',\n",
       " 't_r',\n",
       " 'target_affine',\n",
       " 'target_shape',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(first_level_models[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity(img_path):\n",
    "    filename = Path(img_path).stem\n",
    "    entity = {}\n",
    "    for z in filename.split('_'):\n",
    "        if '-' in z:\n",
    "            key,val = z.split('-')\n",
    "            entity[key] = val\n",
    "    return entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = get_entity(models_run_imgs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "if 'ses' in entity.keys():\n",
    "    kwargs['session'] = entity['ses']\n",
    "if 'run' in entity.keys():\n",
    "    kwargs['run'] = entity['run']\n",
    "kwargs['subject'] = entity['sub']\n",
    "\n",
    "kwargs['task'] = task_name\n",
    "kwargs['desc'] = process_name\n",
    "kwargs['suffix'] = 'modulation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_table(mbmvpa_layout.get(**kwargs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-based-fmri-A7ELC43w-py3.7",
   "language": "python",
   "name": "model-based-fmri-a7elc43w-py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
