{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import bids\n",
    "from bids import BIDSLayout, BIDSValidator\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nilearn as nil\n",
    "\n",
    "from nilearn.image import resample_to_img, resample_img\n",
    "from nilearn.datasets import load_mni152_template, load_mni152_brain_mask\n",
    "from nilearn.glm.first_level.hemodynamic_models import compute_regressor\n",
    "import nibabel as nib\n",
    "\n",
    "from skimage.measure import block_reduce\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "from scipy.stats import ttest_1samp, ttest_ind, t, sem\n",
    "import hbayesdm.models\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import model_based_mvpa as mbmvpa\n",
    "from model_based_mvpa.preprocessing.bids import *\n",
    "from model_based_mvpa.preprocessing.events import *\n",
    "from model_based_mvpa.utils.func import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids.config.set_option('extension_initial_dot', True)\n",
    "\n",
    "args = {\n",
    "    'root': '/data2/project_model_based_fmri/ds000005/',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        bids preprocessing done!        : 100%|██████████| 4/4 [00:54<00:00, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 55, 46)\n",
      "(6810,)\n",
      "time elapsed: 54.48217535018921 seconds\n",
      "time elapsed: 54.48903965950012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X, masked_data = bids_preprocess(args['root'], single_file=True, smoothing_fwhm=None, zoom=(2, 2, 2), ncore=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = [adjust_event_columns, calculate_modulation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      hbayesdm doing (model: ra_prospect)..      :  33%|███▎      | 2/6 [00:14<00:40, 10.12s/it]INFO:numexpr.utils:Note: detected 88 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "INFO:numexpr.utils:Note: NumExpr detected 88 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached StanModel: cached-ra_prospect-pystan_2.19.1.1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Automatic Differentiation Variational Inference (ADVI) is an EXPERIMENTAL ALGORITHM.\n",
      "WARNING:pystan:ADVI samples may be found on the filesystem in the file `/tmp/tmp_jyhw8a5/output.csv`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model  = ra_prospect\n",
      "Data   = <pandas.DataFrame object>\n",
      "\n",
      "Details:\n",
      " # of chains                    = 4\n",
      " # of cores used                = 4\n",
      " # of MCMC samples (per chain)  = 4000\n",
      " # of burn-in samples           = 1000\n",
      " # of subjects                  = 16\n",
      " # of (max) trials per subject  = 256\n",
      "\n",
      "Using cached StanModel: cached-ra_prospect-pystan_2.19.1.1.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       modulation signal making..       :  67%|██████▋   | 4/6 [34:41<20:54, 627.14s/it]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['onset', 'duration', 'parametric loss', 'distance from indifference',\n",
      "       'parametric gain', 'gain', 'loss', 'ptval', 'respnum', 'respcat',\n",
      "       'responsetime', 'run', 'subjid', 'gamble', 'cert'],\n",
      "      dtype='object')\n",
      "['onset', 'duration', 'parametric loss', 'distance from indifference', 'parametric gain', 'gain', 'loss', 'PTval', 'respnum', 'respcat', 'response_time', 'run', 'subjID', 'gamble', 'cert']\n",
      "************************************\n",
      "**** Model fitting is complete! ****\n",
      "************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       events preproecssing done!       : 100%|██████████| 6/6 [34:41<00:00, 346.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 2081.8706233501434 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "a, b, y = preprocess_events(args['root'], dm_model='ra_prospect', funcs=funcs, ncore=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 3, 240, 6810) (16, 3, 240, 1)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('/data2/project_model_based_fmri/ds000005/derivatives/fmriprep/data/X.npy')\n",
    "y = np.load('/data2/project_model_based_fmri/ds000005/derivatives/fmriprep/data/y.npy')\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = prepare_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11520, 6810), (11520, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "from tensorflow.keras import Sequential, layers, losses, optimizers, datasets\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, ReLU\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, X, y, batch_size, shuffle=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(X.shape[0])\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    # for printing the statistics of the function\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        \n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"Denotes the number of batches per epoch\"\n",
    "        \n",
    "        return int(np.floor(len(self.indexes) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):  # index : batch no.\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        niis = [X[i] for i  in indexes]\n",
    "        targets = [y[i] for i in indexes]\n",
    "        niis = np.array(niis)\n",
    "        targets = np.array(targets)\n",
    "\n",
    "        return niis, targets  # return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "lambda_par = 0\n",
    "repeat_N = 100\n",
    "batch_size = 64\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16, 3, 240, 6810), (16, 3, 240, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11520, 6810) (11520, 1)\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(48 * 240, -1)\n",
    "y = y.reshape(48 * 240, -1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.463965189594633, -15.18786072305404)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max(), X.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., ..., 1., 0., 0.],\n",
       "        [0., 0., 2., ..., 1., 0., 0.],\n",
       "        [0., 0., 1., ..., 1., 0., 0.]]),\n",
       " array([-15.18786072, -12.22267813,  -9.25749554,  -6.29231295,\n",
       "         -3.32713036,  -0.36194777,   2.60323482,   5.56841742,\n",
       "          8.53360001,  11.4987826 ,  14.46396519]),\n",
       " <a list of 6810 BarContainer objects>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.7056 - val_loss: 0.7086\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.3282 - val_loss: 0.2087\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2009 - val_loss: 0.1803\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1856 - val_loss: 0.1415\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2752 - val_loss: 0.2987\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1716 - val_loss: 0.1243\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1330 - val_loss: 0.1247\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1281 - val_loss: 0.0932\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1213 - val_loss: 0.0805\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1237 - val_loss: 0.1311\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2172 - val_loss: 0.1409\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1327 - val_loss: 0.1104\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1110 - val_loss: 0.1295\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1686 - val_loss: 0.1176\n",
      "INFO [1/100] - mse: 0.082\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.7358 - val_loss: 0.3800\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.3539 - val_loss: 0.2151\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2010 - val_loss: 0.1655\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1418 - val_loss: 0.1310\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1706 - val_loss: 0.1422\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1356 - val_loss: 0.1282\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1357 - val_loss: 0.1724\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1343 - val_loss: 0.1375\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.1264 - val_loss: 0.1166\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1675 - val_loss: 0.2006\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.1956 - val_loss: 0.1329\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1382 - val_loss: 0.1646\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.2845 - val_loss: 0.1503\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1460 - val_loss: 0.1106\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2069 - val_loss: 0.1495\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1081 - val_loss: 0.0946\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1602 - val_loss: 0.1242\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.3946 - val_loss: 0.4057\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2021 - val_loss: 0.1151\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1033 - val_loss: 0.0754\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1015 - val_loss: 0.0888\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1255 - val_loss: 0.0868\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1085 - val_loss: 0.0906\n",
      "Epoch 24/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1337 - val_loss: 0.0954\n",
      "Epoch 25/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1028 - val_loss: 0.1220\n",
      "INFO [2/100] - mse: 0.078\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.6941 - val_loss: 0.3665\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.3565 - val_loss: 0.2092\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1981 - val_loss: 0.1533\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1434 - val_loss: 0.1389\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1479 - val_loss: 0.1181\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1502 - val_loss: 0.1883\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1285 - val_loss: 0.1569\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1401 - val_loss: 0.1260\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1472 - val_loss: 0.1266\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1572 - val_loss: 0.1367\n",
      "INFO [3/100] - mse: 0.119\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.7042 - val_loss: 0.3494\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.3226 - val_loss: 0.2245\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2408 - val_loss: 0.1874\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1541 - val_loss: 0.1612\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1434 - val_loss: 0.1097\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2338 - val_loss: 0.2718\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.2041 - val_loss: 0.1004\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.0985 - val_loss: 0.1001\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1409 - val_loss: 0.1142\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1214 - val_loss: 0.1123\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1981 - val_loss: 0.2386\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1463 - val_loss: 0.1097\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1810 - val_loss: 0.2050\n",
      "INFO [4/100] - mse: 0.105\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.7419 - val_loss: 0.4523\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.3092 - val_loss: 0.2143\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2218 - val_loss: 0.1954\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1717 - val_loss: 0.1320\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1166 - val_loss: 0.1081\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2313 - val_loss: 0.2827\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2292 - val_loss: 0.1063\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1373 - val_loss: 0.0955\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.0962 - val_loss: 0.0895\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1238 - val_loss: 0.1027\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1054 - val_loss: 0.1110\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1323 - val_loss: 0.1329\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1929 - val_loss: 0.2172\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1685 - val_loss: 0.1168\n",
      "INFO [5/100] - mse: 0.086\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.7444 - val_loss: 0.4534\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.4552 - val_loss: 0.3916\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2025 - val_loss: 0.1309\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2035 - val_loss: 0.2612\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1537 - val_loss: 0.1238\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.0940 - val_loss: 0.1130\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1018 - val_loss: 0.1129\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.1200 - val_loss: 0.1206\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1250 - val_loss: 0.1149\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2285 - val_loss: 0.1761\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1392 - val_loss: 0.1060\n",
      "Epoch 12/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1987 - val_loss: 0.1635\n",
      "Epoch 13/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2032 - val_loss: 0.1486\n",
      "Epoch 14/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.3664 - val_loss: 0.3695\n",
      "Epoch 15/100\n",
      "144/144 [==============================] - 1s 3ms/step - loss: 0.2148 - val_loss: 0.0829\n",
      "Epoch 16/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.1560 - val_loss: 0.0908\n",
      "Epoch 17/100\n",
      "144/144 [==============================] - 1s 5ms/step - loss: 0.0898 - val_loss: 0.1239\n",
      "Epoch 18/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.1231 - val_loss: 0.0805\n",
      "Epoch 19/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.0967 - val_loss: 0.1105\n",
      "Epoch 20/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1398 - val_loss: 0.1504\n",
      "Epoch 21/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1613 - val_loss: 0.1174\n",
      "Epoch 22/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1525 - val_loss: 0.1496\n",
      "Epoch 23/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1794 - val_loss: 0.1302\n",
      "INFO [6/100] - mse: 0.082\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.7777 - val_loss: 0.3347\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2931 - val_loss: 0.2286\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2194 - val_loss: 0.1355\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1419 - val_loss: 0.1695\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1328 - val_loss: 0.1178\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1200 - val_loss: 0.1320\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1401 - val_loss: 0.2024\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2091 - val_loss: 0.1428\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2625 - val_loss: 0.1191\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1271 - val_loss: 0.3263\n",
      "INFO [7/100] - mse: 0.110\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.7454 - val_loss: 0.3339\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2956 - val_loss: 0.3140\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2687 - val_loss: 0.1864\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1499 - val_loss: 0.1155\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1303 - val_loss: 0.1779\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1185 - val_loss: 0.0971\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1299 - val_loss: 0.1378\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1437 - val_loss: 0.2140\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.1464 - val_loss: 0.1102\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1388 - val_loss: 0.1401\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.1358 - val_loss: 0.1351\n",
      "INFO [8/100] - mse: 0.102\n",
      "Epoch 1/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.7632 - val_loss: 0.3882\n",
      "Epoch 2/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.3207 - val_loss: 0.2816\n",
      "Epoch 3/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2181 - val_loss: 0.1535\n",
      "Epoch 4/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1472 - val_loss: 0.1266\n",
      "Epoch 5/100\n",
      "144/144 [==============================] - 1s 4ms/step - loss: 0.1589 - val_loss: 0.3920\n",
      "Epoch 6/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1685 - val_loss: 0.1085\n",
      "Epoch 7/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1551 - val_loss: 0.0946\n",
      "Epoch 8/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1015 - val_loss: 0.1530\n",
      "Epoch 9/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1375 - val_loss: 0.1141\n",
      "Epoch 10/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.2471 - val_loss: 0.2903\n",
      "Epoch 11/100\n",
      "144/144 [==============================] - 0s 3ms/step - loss: 0.1523 - val_loss: 0.1242\n",
      "Epoch 12/100\n",
      " 96/144 [===================>..........] - ETA: 0s - loss: 0.1154"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-e1c93b472b36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                         verbose=1, callbacks=[EarlyStopping(monitor='val_loss', patience=5), model_checkpoint])\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mva/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mva/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/anaconda3/envs/mva/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mva/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mva/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mva/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mva/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mva/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mva/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mva/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_build_call_outputs\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m   2168\u001b[0m     \u001b[0;31m# Replace outputs with results, skipping over any 'None' values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m     outputs_list = nest.flatten(\n\u001b[0;32m-> 2170\u001b[0;31m         self._func_graph.structured_outputs, expand_composites=True)\n\u001b[0m\u001b[1;32m   2171\u001b[0m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mva/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mnest\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m   \"\"\"\n\u001b[0;32m--> 338\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "coeffs = []\n",
    "\n",
    "for repeat_i in range(repeat_N):\n",
    "    ids = np.arange(X.shape[0])\n",
    "    train_ids, test_ids = train_test_split(ids, test_size=0.2, random_state=42 + repeat_i)\n",
    "    train_steps = len(train_ids) // batch_size\n",
    "    valid_steps = len(test_ids) // batch_size\n",
    "\n",
    "    X_train = X[train_ids]\n",
    "    y_train = y[train_ids]\n",
    "    X_test = X[test_ids]\n",
    "    y_test = y[test_ids]\n",
    "    \n",
    "    train_generator = DataGenerator(X_train, y_train, batch_size, shuffle=True)\n",
    "    valid_generator = DataGenerator(X_test, y_test, batch_size, shuffle=False)\n",
    "    \n",
    "    bst_model_path = f'ml_models/{repeat_i}_best_elasticnet_alpha{alpha:0.3f}_lambda{lambda_par:0.2f}.h5'\n",
    "    model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True,monitor='val_loss',mode='min',)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, activation='linear', input_shape=(X.shape[-1],),\n",
    "                    use_bias=True,\n",
    "                    kernel_regularizer=l1_l2(lambda_par*alpha,lambda_par*(1-alpha)/2),)) \n",
    "    model.compile(loss='mse', optimizer='adam',)\n",
    "    \n",
    "    model.fit_generator(generator=train_generator, validation_data=valid_generator,\n",
    "                        steps_per_epoch=train_steps, validation_steps=valid_steps,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1, callbacks=[EarlyStopping(monitor='val_loss', patience=5), model_checkpoint])\n",
    "    model.load_weights(bst_model_path)\n",
    "        \n",
    "    pred = model(X_test).numpy()\n",
    "    mse = ((pred-y_test)**2).mean()\n",
    "    print(f'INFO [{repeat_i+1}/{repeat_N}] - mse: {mse:.03f}')\n",
    "    coeff = model.layers[0].get_weights()[0]  \n",
    "    coeffs.append(coeff)\n",
    "    \n",
    "#coeffs = np.array(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = np.array(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO [0.001]: done! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mybirth0407/anaconda3/envs/mva/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "t_val = ttest_1samp(coeffs,0).statistic\n",
    "\n",
    "t_map = np.zeros(masked_data.get_fdata().flatten().shape[0])\n",
    "\n",
    "for i, v in zip(np.nonzero(masked_data.get_fdata().flatten())[0] ,t_val):\n",
    "    t_map[i] = v\n",
    "    \n",
    "t_map = t_map.reshape(masked_data.shape)\n",
    "\n",
    "# t_map = resize(t_map,(masked_data.shape))\n",
    "\n",
    "t_map *= masked_data.get_data()\n",
    "nii_i = nib.Nifti1Image(t_map, affine=masked_data.affine)\n",
    "\n",
    "nii_i.to_filename(f'elasticnet_keras_masked_alpha{alpha:0.3f}_lambda{lambda_par:0.4f}.nii')\n",
    "\n",
    "print(f'INFO [{alpha}]: done! ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (MVPA)",
   "language": "python",
   "name": "mvpa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
