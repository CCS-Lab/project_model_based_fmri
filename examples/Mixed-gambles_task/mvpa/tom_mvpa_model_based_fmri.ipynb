{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is an MB-MVPA code that uses part of the data (Tom et al., 2007).<br>\n",
    "Tom's full dataset used 16 subjects, but in this example, only 2 subjects are used to save resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the MB-MVPA libarary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other libraries(nilean, keras, etc..) dosen't need to be imported.<br>\n",
    "Because mb-mvpa has wrapping the libararies.<br>\n",
    "You don't necessarily have to know fMRI libraries like nilearn and machine learning libraries like tensorflow.<br>\n",
    "<b>MB-MVPA is all you need.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of mb-mvpa are wrapping nilearn, tensorflow, Keras and etc., so warning can occur from that libraries.<br>\n",
    "This page does not print warning because most of them are can be ignored.<br>\n",
    "<b> You do not need to remove the warning when you are actually using it. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.preprocessing.bids import bids_preprocess\n",
    "from mbmvpa.preprocessing.events import events_preprocess\n",
    "from mbmvpa.data.loader import prepare_dataset\n",
    "from mbmvpa.utils.example_utils import load_example_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data download from AWS S3, ~ 1GB.<br>\n",
    "If you run this example more than once, the data will already be downloaded.<br>\n",
    "If so, do not download it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load success! (tom)\n"
     ]
    }
   ],
   "source": [
    "root = load_example_data(\"tom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing bids data including fMRI images\n",
    "The MB-MVPA liabrary need to BIDS format including preprocessed nii images*(nii or nii.gz)* and behavior data file*(.tsv)*.<br>\n",
    "The fMRI images are usually located here<br>\n",
    "**derivatives/fmriprep/**<br>\n",
    "And the behavior data are located here<br>\n",
    "**subject/session/run/func**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bids preprocessing done!                          : 100%|██████████| 6/6 [00:19<00:00,  3.25s/it]  \n"
     ]
    }
   ],
   "source": [
    "X, voxel_mask, layout, data_root = bids_preprocess(root, smoothing_fwhm=None, zoom=(2, 2, 2), ncore=2, nthread=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>X</b> (numpy.array): subject-wise & run-wise BOLD time series data. shape : subject # x run # x timepoint # x voxel #.<br>\n",
    "<b>voxel_mask</b> (nibabel.Nifti1Image): a nifti image for voxel-wise binary mask (ROI mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our mbmvpa is directly inputted into the data and modulation functions to be used to increase user's freedom and increase stability.<br>\n",
    "The following three functions must be completed, each of which means:<br>\n",
    "1. If you use **hbayesDM**, you should change the columns name to suit it. -> preprocess\n",
    "2. If you only want to use behavioral data under certain conditions, you must define a condition function. -> condition\n",
    "3. Finally, since we are model-based fMRI, we have to calculate the modulation.<br>\n",
    "   The important point is that the behavioral data that we already have are in the **\"row\"**, and parameters estimated by model are in the **\"param_dict\"**.<br>\n",
    "   -> modulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''' python\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have parameters already calculated and can provide them in *.tsv*, we also allow that.<br>\n",
    "\"**individual_params_custom\"** has the role.<br>\n",
    "In that case, the dm_model, or deicison making model, is not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_tom_modulation(row, param_dict):\n",
    "    ## calculate subjectives utility for choosing Gamble over Safe option\n",
    "    ## prospect theory with loss aversion and risk aversion is adopted\n",
    "    modulation = (row[\"gain\"] ** param_dict[\"rho\"]) - (param_dict[\"lambda\"] * (row[\"loss\"] ** param_dict[\"rho\"]))\n",
    "    row[\"modulation\"] = modulation\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calculating modulation..                          :  83%|████████▎ | 5/6 [00:02<00:00,  1.23it/s]  INFO:numexpr.utils:Note: detected 88 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "INFO:numexpr.utils:Note: NumExpr detected 88 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "events preproecssing done!                        : : 7it [00:03,  2.25it/s]                     \n"
     ]
    }
   ],
   "source": [
    "dm_model, df_events, signals, time_masks, _ = \\\n",
    "    events_preprocess(root,\n",
    "                      modulation=example_tom_modulation,\n",
    "                      individual_params_custom=\"../example_data/tom_example/derivatives/fmriprep/mvpa/individual_params.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and shape check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the above process, **X(fMRI images)** and **Y(modulation)** dataset can be obtained.<br>\n",
    "Their shape[0] is must be equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, voxel_mask = prepare_dataset(data_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting MVPA models & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.utils.coef2map import get_map\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[1/10] - val_mse: 0.1820\n",
      "INFO:root:[2/10] - val_mse: 0.1726\n",
      "INFO:root:[3/10] - val_mse: 0.1606\n",
      "INFO:root:[4/10] - val_mse: 0.1851\n",
      "INFO:root:[5/10] - val_mse: 0.1644\n",
      "INFO:root:[6/10] - val_mse: 0.1523\n",
      "INFO:root:[7/10] - val_mse: 0.1453\n",
      "INFO:root:[8/10] - val_mse: 0.1732\n",
      "INFO:root:[9/10] - val_mse: 0.1685\n"
     ]
    }
   ],
   "source": [
    "from mbmvpa.models.regressor import penalized_linear_regression\n",
    "\n",
    "s = perf_counter()\n",
    "coefs = penalized_linear_regression(X, y,\n",
    "                                    layout,\n",
    "                                    lambda_param=2.0,\n",
    "                                    batch_size=256,\n",
    "                                    N=10,\n",
    "                                    verbose=1)\n",
    "result = get_map(coefs, voxel_mask, task_name=\"tom2007_penalized_linear\", map_type=\"z\", save_path=\".\", sigma=1)\n",
    "print(f\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.models.regressor import mlp_regression\n",
    "\n",
    "s = perf_counter()\n",
    "coefs = mlp_regression(X, y,\n",
    "                       layout,\n",
    "                       layer_dims=[1024, 1024],\n",
    "                       activation=\"linear\",\n",
    "                       dropout_rate=0.5,\n",
    "                       epochs=100,\n",
    "                       patience=10,\n",
    "                       batch_size=64,\n",
    "                       N=3,\n",
    "                       verbose=1)\n",
    "result = get_map(coefs, voxel_mask, task_name=\"tom2007_mlp\", map_type=\"z\", save_path=\".\", sigma=1)\n",
    "print(f\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mbmvpa.models.regressor import elasticnet\n",
    "\n",
    "s = perf_counter()\n",
    "coefs = elasticnet(X, y,\n",
    "                   layout,\n",
    "                   n_jobs=16,\n",
    "                   verbose=1,\n",
    "                   max_lambda=1,\n",
    "                   n_samples=5000)\n",
    "result = get_map(coefs, voxel_mask, task_name=\"tom2007_elasticnet\", map_type=\"z\", save_path=\".\", sigma=1)\n",
    "print(f\"elapsed time: {(perf_counter()-s) / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (MVPA)",
   "language": "python",
   "name": "mvpa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
